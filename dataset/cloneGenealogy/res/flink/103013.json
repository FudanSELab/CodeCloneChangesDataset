[{"authorTime":"2020-10-14 17:24:20","codes":[{"authorDate":"2020-10-14 17:24:20","commitOrder":1,"curCode":"\tpublic void testOneInputTransformation() {\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tSingleOutputStreamOperator<Integer> process = env.fromElements(1, 2)\n\t\t\t.keyBy(Integer::intValue)\n\t\t\t.process(DUMMY_PROCESS_FUNCTION);\n\t\tDataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n\t\tStreamGraphGenerator graphGenerator = new StreamGraphGenerator(\n\t\t\tCollections.singletonList(sink.getTransformation()),\n\t\t\tenv.getConfig(),\n\t\t\tenv.getCheckpointConfig()\n\t\t);\n\t\tgraphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n\t\tStreamGraph graph = graphGenerator.generate();\n\t\tStreamNode processNode = graph.getStreamNode(process.getId());\n\t\tassertThat(processNode.getSortedInputs(), equalTo(true));\n\t\tassertThat(processNode.getOperatorFactory().getChainingStrategy(), equalTo(ChainingStrategy.HEAD));\n\t\tassertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n\t\t\r\n\t\tassertThat(graph.getTimerServiceProvider(), notNullValue());\n\t}\n","date":"2020-10-16 21:55:31","endLine":93,"groupId":"13310","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testOneInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/40/95ad5ff912f3331a2113ebcd141cba28b0d5a0.src","preCode":"\tpublic void testOneInputTransformation() {\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tSingleOutputStreamOperator<Integer> process = env.fromElements(1, 2)\n\t\t\t.keyBy(Integer::intValue)\n\t\t\t.process(DUMMY_PROCESS_FUNCTION);\n\t\tDataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n\t\tStreamGraphGenerator graphGenerator = new StreamGraphGenerator(\n\t\t\tCollections.singletonList(sink.getTransformation()),\n\t\t\tenv.getConfig(),\n\t\t\tenv.getCheckpointConfig()\n\t\t);\n\t\tgraphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n\t\tStreamGraph graph = graphGenerator.generate();\n\t\tStreamNode processNode = graph.getStreamNode(process.getId());\n\t\tassertThat(processNode.getSortedInputs(), equalTo(true));\n\t\tassertThat(processNode.getOperatorFactory().getChainingStrategy(), equalTo(ChainingStrategy.HEAD));\n\t\tassertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n\t\t\r\n\t\tassertThat(graph.getTimerServiceProvider(), notNullValue());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":72,"status":"B"},{"authorDate":"2020-10-14 17:24:20","commitOrder":1,"curCode":"\tpublic void testTwoInputTransformation() {\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tDataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n\t\tDataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n\t\tSingleOutputStreamOperator<Integer> process = elements1.connect(elements2)\n\t\t\t.keyBy(Integer::intValue, Integer::intValue)\n\t\t\t.process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n\t\tDataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n\t\tStreamGraphGenerator graphGenerator = new StreamGraphGenerator(\n\t\t\tCollections.singletonList(sink.getTransformation()),\n\t\t\tenv.getConfig(),\n\t\t\tenv.getCheckpointConfig()\n\t\t);\n\t\tgraphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n\t\tStreamGraph graph = graphGenerator.generate();\n\t\tStreamNode processNode = graph.getStreamNode(process.getId());\n\t\tassertThat(processNode.getSortedInputs(), equalTo(true));\n\t\tassertThat(processNode.getOperatorFactory().getChainingStrategy(), equalTo(ChainingStrategy.HEAD));\n\t\tassertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n\t\t\r\n\t\tassertThat(graph.getTimerServiceProvider(), notNullValue());\n\t}\n","date":"2020-10-16 21:55:31","endLine":194,"groupId":"13310","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testTwoInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/40/95ad5ff912f3331a2113ebcd141cba28b0d5a0.src","preCode":"\tpublic void testTwoInputTransformation() {\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tDataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n\t\tDataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n\t\tSingleOutputStreamOperator<Integer> process = elements1.connect(elements2)\n\t\t\t.keyBy(Integer::intValue, Integer::intValue)\n\t\t\t.process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n\t\tDataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n\t\tStreamGraphGenerator graphGenerator = new StreamGraphGenerator(\n\t\t\tCollections.singletonList(sink.getTransformation()),\n\t\t\tenv.getConfig(),\n\t\t\tenv.getCheckpointConfig()\n\t\t);\n\t\tgraphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n\t\tStreamGraph graph = graphGenerator.generate();\n\t\tStreamNode processNode = graph.getStreamNode(process.getId());\n\t\tassertThat(processNode.getSortedInputs(), equalTo(true));\n\t\tassertThat(processNode.getOperatorFactory().getChainingStrategy(), equalTo(ChainingStrategy.HEAD));\n\t\tassertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n\t\t\r\n\t\tassertThat(graph.getTimerServiceProvider(), notNullValue());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":171,"status":"B"}],"commitId":"2ff3b771cbb091e1f43686dd8e176cea6d435501","commitMessage":"@@@[FLINK-19640] Enable sorting inputs for batch\n\nThis PR adds feature flags for enabling/disabling the sorting inputs and\nspecial types of a state backend and a timer service for BATCH execution\nruntime. Those options are enabled by default for BATCH runtime\nexecution mode.\n","date":"2020-10-16 21:55:31","modifiedFileCount":"9","status":"B","submitter":"Dawid Wysakowicz"},{"authorTime":"2020-12-10 22:07:57","codes":[{"authorDate":"2020-12-10 22:07:57","commitOrder":2,"curCode":"    public void testOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","date":"2021-01-07 19:11:45","endLine":108,"groupId":"13310","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testOneInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/89283442f9ab8757394dcd79734e1cf2a606a3.src","preCode":"    public void testOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(processNode.getSortedInputs(), equalTo(true));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2020-12-10 22:07:57","commitOrder":2,"curCode":"    public void testTwoInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        DataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n        DataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n        SingleOutputStreamOperator<Integer> process =\n                elements1\n                        .connect(elements2)\n                        .keyBy(Integer::intValue, Integer::intValue)\n                        .process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getInputRequirements().get(1),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","date":"2021-01-07 19:11:45","endLine":220,"groupId":"13310","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testTwoInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/89283442f9ab8757394dcd79734e1cf2a606a3.src","preCode":"    public void testTwoInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        DataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n        DataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n        SingleOutputStreamOperator<Integer> process =\n                elements1\n                        .connect(elements2)\n                        .keyBy(Integer::intValue, Integer::intValue)\n                        .process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(processNode.getSortedInputs(), equalTo(true));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":188,"status":"M"}],"commitId":"524a10708aed7f9c67cccba909d489e8d14a633f","commitMessage":"@@@[FLINK-20491] Add per-input setting of BATCH execution requirements\n\nThis doesn't change the actual behavior.  we still set the same \"sorted\"\nsetting on both inputs. We will add tests and actually change the\nbehavior in a follow-up commit.\n","date":"2021-01-07 19:11:45","modifiedFileCount":"14","status":"M","submitter":"Aljoscha Krettek"},{"authorTime":"2021-08-12 00:09:10","codes":[{"authorDate":"2021-08-12 00:09:10","commitOrder":3,"curCode":"    public void testOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraph graph = getStreamGraphInBatchMode(sink);\n\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","date":"2021-08-13 23:14:56","endLine":186,"groupId":"103013","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testOneInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c3/a11115c73e4b56f4512869dcc841b1eac70b24.src","preCode":"    public void testOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":167,"status":"M"},{"authorDate":"2021-08-12 00:09:10","commitOrder":3,"curCode":"    public void testTwoInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n        DataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n        DataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n        SingleOutputStreamOperator<Integer> process =\n                elements1\n                        .connect(elements2)\n                        .keyBy(Integer::intValue, Integer::intValue)\n                        .process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraph graph = getStreamGraphInBatchMode(sink);\n\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getInputRequirements().get(1),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","date":"2021-08-13 23:14:56","endLine":277,"groupId":"103013","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"testTwoInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c3/a11115c73e4b56f4512869dcc841b1eac70b24.src","preCode":"    public void testTwoInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        DataStreamSource<Integer> elements1 = env.fromElements(1, 2);\n        DataStreamSource<Integer> elements2 = env.fromElements(1, 2);\n        SingleOutputStreamOperator<Integer> process =\n                elements1\n                        .connect(elements2)\n                        .keyBy(Integer::intValue, Integer::intValue)\n                        .process(DUMMY_KEYED_CO_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig());\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getInputRequirements().get(1),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), instanceOf(BatchExecutionStateBackend.class));\n        \r\n        assertThat(graph.getTimerServiceProvider(), notNullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"}],"commitId":"0875db3559afdb847d02de585ad7348b39eee053","commitMessage":"@@@[FLINK-20897][table-planner] Support batch mode in StreamTableEnvironment\n\nThis enables batch mode for StreamTableEnvironment.\n\nBoth StreamExecutionEnvironment.  TableEnvironment.  and StreamTableEnvironment\nuse StreamGraphGenerator with the same configuration. Previous work ensured\nthat when execution.runtime-mode is set to BATCH all batch properties are\neither set consistently (e.g. shuffle mode) or have no impact on the pipeline\n(e.g. auto watermark interval.  state backends).\n\nMost of the changes are removing checks and ensuring that internal (e.g. values)\nand external (e.g. data stream.  table source) source transformations are set\nto BOUNDED. The latter is a complex topic as we currently use 4 different ways\nof expressing external sources:\n\n- InputFormatProvider: Boundedness needs to be explicitly set by the planner\ndue to custom formats that don't extend from FileInputFormat.\n- SourceFunctionProvider: Boundedness needs to be explicitly set by the planner\nvia custom transformation to also disable progressive watermarks.\n- DataStreamScanProvider: Boundedness needs to be explicitly set by the planner\nto ensure old behavior again. New source interfaces + FileInputFormat are fine.\n- TransformationScanProvider: Boundedness can be derived automatically and will\nonly work with new source interfaces + FileInputFormat.\n\nThis closes #16793.\n","date":"2021-08-13 23:14:56","modifiedFileCount":"18","status":"M","submitter":"Timo Walther"}]
