[{"authorTime":"2017-12-07 03:38:38","codes":[{"authorDate":"2017-12-07 03:38:38","commitOrder":1,"curCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","date":"2017-12-07 03:38:38","endLine":181,"groupId":"20084","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBetweenBeginningAndEndOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/b0f5f82526b0ab60ab3c066532578eb67da0f9.src","preCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"B"},{"authorDate":"2017-12-07 03:38:38","commitOrder":1,"curCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","date":"2017-12-07 03:38:38","endLine":199,"groupId":"20084","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBeforeBeginningOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/b0f5f82526b0ab60ab3c066532578eb67da0f9.src","preCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":184,"status":"B"}],"commitId":"30f08d158a97e0d83b59e5910fbb0a84c5c6d14f","commitMessage":"@@@KAFKA-5520: KIP-171; Extend Consumer Group Reset Offset for Stream Application\n\nKIP: https://cwiki.apache.org/confluence/display/KAFKA/KIP-171+-+Extend+Consumer+Group+Reset+Offset+for+Stream+Application\n\nMerge changes from KIP-198\n\nRef: https://github.com/apache/kafka/pull/3831\n\nAuthor: Jorge Quilcate Otoya <quilcate.jorge@gmail.com>\nAuthor: Ismael Juma <ismael@juma.me.uk>\nAuthor: Matthias J. Sax <matthias@confluent.io>\nAuthor: Manikumar Reddy <manikumar.reddy@gmail.com>\nAuthor: Guozhang Wang <wangguoz@gmail.com>\nAuthor: Apurva Mehta <apurva@confluent.io>\nAuthor: Rajini Sivaram <rajinisivaram@googlemail.com>\nAuthor: Jason Gustafson <jason@confluent.io>\nAuthor: Vahid Hashemian <vahidhashemian@us.ibm.com>\nAuthor: Bill Bejeck <bill@confluent.io>\nAuthor: Dong Lin <lindong28@gmail.com>\nAuthor: Soenke Liebau <soenke.liebau@opencore.com>\nAuthor: Colin P. Mccabe <cmccabe@confluent.io>\nAuthor: Damian Guy <damian.guy@gmail.com>\nAuthor: Xavier L?aut? <xl+github@xvrl.net>\nAuthor: Maytee Chinavanichkit <maytee.chinavanichkit@linecorp.com>\nAuthor: Joel Hamill <git config --global user.email>\nAuthor: Paolo Patierno <ppatierno@live.com>\nAuthor: siva santhalingam <siva.santhalingam@gmail.com>\nAuthor: Tommy Becker <tobecker@tivo.com>\nAuthor: Mickael Maison <mickael.maison@gmail.com>\nAuthor: Onur Karaman <okaraman@linkedin.com>\nAuthor: tedyu <yuzhihong@gmail.com>\nAuthor: Xin Li <Xin.Li@trivago.com>\nAuthor: Magnus Edenhill <magnus@edenhill.se>\nAuthor: Manjula K <manjula@kafka-summit.org>\nAuthor: Hugo Louro <hmclouro@gmail.com>\nAuthor: Jeff Widman <jeff@jeffwidman.com>\nAuthor: bartdevylder <bartdevylder@gmail.com>\nAuthor: Ewen Cheslack-Postava <me@ewencp.org>\nAuthor: Jacek Laskowski <jacek@japila.pl>\nAuthor: Tom Bentley <tbentley@redhat.com>\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>\n\nCloses #4159 from jeqo/feature/kip-171\n","date":"2017-12-07 03:38:38","modifiedFileCount":"4","status":"B","submitter":"Jorge Quilcate Otoya"},{"authorTime":"2018-05-05 00:02:50","codes":[{"authorDate":"2018-05-05 00:02:50","commitOrder":2,"curCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = poll(consumer, 500);\n        assertEquals(2, records.count());\n    }\n","date":"2018-05-05 00:05:53","endLine":178,"groupId":"20084","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBetweenBeginningAndEndOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/49/f699ec658cb10a5911c8d18396efe8faabb8f2.src","preCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"M"},{"authorDate":"2018-05-05 00:02:50","commitOrder":2,"curCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = poll(consumer, 500);\n        assertEquals(2, records.count());\n    }\n","date":"2018-05-05 00:05:53","endLine":196,"groupId":"20084","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBeforeBeginningOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/49/f699ec658cb10a5911c8d18396efe8faabb8f2.src","preCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":181,"status":"M"}],"commitId":"2d8049b713f2b9982bd43e7340a0e0f302f30d6b","commitMessage":"@@@KAFKA-5697: issue Consumer#wakeup during Streams shutdown\n\nWakeup consumers during shutdown to break them out of any internally blocking calls.\n\nSemantically.  it should be fine to treat a WakeupException as \"no work to do\".  which will then continue the threads' polling loops.  leading them to discover that they are supposed to shut down.  which they will do gracefully.\n\nThe existing tests should be sufficient to verify no regressions.\n\nAuthor: John Roesler <john@confluent.io>\n\nReviewers: Bill Bejeck <bbejeck@gmail.com>.  Guozhang Wang <wangguoz@gmail.com>\n\nCloses #4930 from vvcephei/streams-client-wakeup-on-shutdown\n\nminor javadoc updates\n","date":"2018-05-05 00:05:53","modifiedFileCount":"16","status":"M","submitter":"John Roesler"},{"authorTime":"2018-05-18 23:05:09","codes":[{"authorDate":"2018-05-18 23:05:09","commitOrder":3,"curCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","date":"2018-05-18 23:05:09","endLine":177,"groupId":"20084","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBetweenBeginningAndEndOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ad/19f32fd1d740e83611565ef4507b788472a069.src","preCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = poll(consumer, 500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":162,"status":"M"},{"authorDate":"2018-05-18 23:05:09","commitOrder":3,"curCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","date":"2018-05-18 23:05:09","endLine":195,"groupId":"20084","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBeforeBeginningOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/ad/19f32fd1d740e83611565ef4507b788472a069.src","preCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = poll(consumer, 500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"M"}],"commitId":"58a910f0a7e6e2da4af9f1fcebdabeb22d909fcb","commitMessage":"@@@KAFKA-5697: revert wakeup-based impl (#5035)\n\nThe wakeup-based strategy caused more problems than it\nsolved.  so we'll instead focus on KIP-266.\n\nRevert commit 2d8049b.\n\nKeep the metrics addition and the new test util.\n\nAlso keep the tests for shutdown.  although they must be ignored until\npoll(Duration) is done in the scope of KIP-266.\n\nReviewers: Guozhang Wang <wangguoz@gmail.com>","date":"2018-05-18 23:05:09","modifiedFileCount":"14","status":"M","submitter":"John Roesler"},{"authorTime":"2018-06-09 01:54:26","codes":[{"authorDate":"2018-06-09 01:54:26","commitOrder":4,"curCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(Duration.ofMillis(500));\n        assertEquals(2, records.count());\n    }\n","date":"2018-06-09 01:54:26","endLine":178,"groupId":"10701","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBetweenBeginningAndEndOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/33/cf1fa34bcf14151fc52f13a2582ec2e73ad1d1.src","preCode":"    public void testResetUsingPlanWhenBetweenBeginningAndEndOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 0L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 3L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":163,"status":"M"},{"authorDate":"2018-06-09 01:54:26","commitOrder":4,"curCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(Duration.ofMillis(500));\n        assertEquals(2, records.count());\n    }\n","date":"2018-06-09 01:54:26","endLine":196,"groupId":"10701","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testResetUsingPlanWhenBeforeBeginningOffset","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/33/cf1fa34bcf14151fc52f13a2582ec2e73ad1d1.src","preCode":"    public void testResetUsingPlanWhenBeforeBeginningOffset() {\n        final Map<TopicPartition, Long> endOffsets = new HashMap<>();\n        endOffsets.put(topicPartition, 4L);\n        consumer.updateEndOffsets(endOffsets);\n\n        final Map<TopicPartition, Long> beginningOffsets = new HashMap<>();\n        beginningOffsets.put(topicPartition, 3L);\n        consumer.updateBeginningOffsets(beginningOffsets);\n\n        final Map<TopicPartition, Long> topicPartitionsAndOffset = new HashMap<>();\n        topicPartitionsAndOffset.put(topicPartition, 1L);\n        streamsResetter.resetOffsetsFromResetPlan(consumer, inputTopicPartitions, topicPartitionsAndOffset);\n\n        final ConsumerRecords<byte[], byte[]> records = consumer.poll(500);\n        assertEquals(2, records.count());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/tools/StreamsResetterTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":181,"status":"M"}],"commitId":"74bdafe386ae6080d6f5ead852f9026061a65be4","commitMessage":"@@@KAFKA-5697: Use nonblocking poll in Streams (#5107)\n\nMake use of the new Consumer#poll(Duration) to avoid getting stuck in poll when the broker is unavailable.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <guozhang@confluent.io>.  Bill Bejeck <bill@confluent.io>","date":"2018-06-09 01:54:26","modifiedFileCount":"19","status":"M","submitter":"John Roesler"}]
