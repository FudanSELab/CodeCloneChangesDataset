[{"authorTime":"2020-05-28 04:55:29","codes":[{"authorDate":"2020-05-28 04:55:29","commitOrder":1,"curCode":"    public void shouldGetRecordLatenessSensor() {\n        final String operation = \"record-lateness\";\n        final String avgDescription =\n            \"The observed average lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        final String maxDescription =\n            \"The observed maximum lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.DEBUG)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addAvgAndMaxToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            avgDescription,\n            maxDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.recordLatenessSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","date":"2020-05-28 04:55:29","endLine":258,"groupId":"12168","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldGetRecordLatenessSensor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/8a5aa26ae76d5b081ae39cee6656d4ddd690f3.src","preCode":"    public void shouldGetRecordLatenessSensor() {\n        final String operation = \"record-lateness\";\n        final String avgDescription =\n            \"The observed average lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        final String maxDescription =\n            \"The observed maximum lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.DEBUG)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addAvgAndMaxToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            avgDescription,\n            maxDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.recordLatenessSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetricsTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":234,"status":"B"},{"authorDate":"2020-05-28 04:55:29","commitOrder":1,"curCode":"    public void shouldGetDroppedRecordsSensor() {\n        final String operation = \"dropped-records\";\n        final String totalDescription = \"The total number of dropped records\";\n        final String rateDescription = \"The average number of dropped records per second\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.INFO)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addInvocationRateAndCountToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            rateDescription,\n            totalDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.droppedRecordsSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","date":"2020-05-28 04:55:29","endLine":281,"groupId":"12168","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldGetDroppedRecordsSensor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/91/8a5aa26ae76d5b081ae39cee6656d4ddd690f3.src","preCode":"    public void shouldGetDroppedRecordsSensor() {\n        final String operation = \"dropped-records\";\n        final String totalDescription = \"The total number of dropped records\";\n        final String rateDescription = \"The average number of dropped records per second\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.INFO)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addInvocationRateAndCountToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            rateDescription,\n            totalDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.droppedRecordsSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetricsTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"B"}],"commitId":"83c616f70694637627edb6b1215738c78b74a50d","commitMessage":"@@@KAFKA-9983: KIP-613: add INFO level e2e latency metrics (#8697)\n\nAdd e2e latency metrics at the beginning and end of task topologies\nas INFO-level processor-node-level metrics.\n\nImplements: KIP-613\nReviewers: John Roesler <vvcephei@apache.org>.  Andrew Choi <a24choi@edu.uwaterloo.ca>.  Bruno Cadonna <cadonna@confluent.io>.  Matthias J. Sax <matthias@confluent.io>","date":"2020-05-28 04:55:29","modifiedFileCount":"17","status":"B","submitter":"A. Sophie Blee-Goldman"},{"authorTime":"2021-06-11 04:21:46","codes":[{"authorDate":"2021-06-11 04:21:46","commitOrder":2,"curCode":"    public void shouldGetRecordLatenessSensor() {\n        final String operation = \"record-lateness\";\n        final String avgDescription =\n            \"The observed average lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        final String maxDescription =\n            \"The observed maximum lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        when(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.DEBUG)).thenReturn(expectedSensor);\n        when(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).thenReturn(tagMap);\n        StreamsMetricsImpl.addAvgAndMaxToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            avgDescription,\n            maxDescription\n        );\n\n        final Sensor sensor = TaskMetrics.recordLatenessSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        assertThat(sensor, is(expectedSensor));\n    }\n","date":"2021-06-11 04:21:46","endLine":207,"groupId":"102363","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"shouldGetRecordLatenessSensor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1d/33fea1ecc0a07524be74bc19496fb1e027a9a9.src","preCode":"    public void shouldGetRecordLatenessSensor() {\n        final String operation = \"record-lateness\";\n        final String avgDescription =\n            \"The observed average lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        final String maxDescription =\n            \"The observed maximum lateness of records in milliseconds, measured by comparing the record timestamp with \"\n                + \"the current stream time\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.DEBUG)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addAvgAndMaxToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            avgDescription,\n            maxDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.recordLatenessSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetricsTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":185,"status":"M"},{"authorDate":"2021-06-11 04:21:46","commitOrder":2,"curCode":"    public void shouldGetDroppedRecordsSensor() {\n        final String operation = \"dropped-records\";\n        final String totalDescription = \"The total number of dropped records\";\n        final String rateDescription = \"The average number of dropped records per second\";\n        when(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.INFO)).thenReturn(expectedSensor);\n        when(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).thenReturn(tagMap);\n        StreamsMetricsImpl.addInvocationRateAndCountToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            rateDescription,\n            totalDescription\n        );\n\n        final Sensor sensor = TaskMetrics.droppedRecordsSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        assertThat(sensor, is(expectedSensor));\n    }\n","date":"2021-06-11 04:21:46","endLine":228,"groupId":"102363","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"shouldGetDroppedRecordsSensor","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/1d/33fea1ecc0a07524be74bc19496fb1e027a9a9.src","preCode":"    public void shouldGetDroppedRecordsSensor() {\n        final String operation = \"dropped-records\";\n        final String totalDescription = \"The total number of dropped records\";\n        final String rateDescription = \"The average number of dropped records per second\";\n        expect(streamsMetrics.taskLevelSensor(THREAD_ID, TASK_ID, operation, RecordingLevel.INFO)).andReturn(expectedSensor);\n        expect(streamsMetrics.taskLevelTagMap(THREAD_ID, TASK_ID)).andReturn(tagMap);\n        StreamsMetricsImpl.addInvocationRateAndCountToSensor(\n            expectedSensor,\n            TASK_LEVEL_GROUP,\n            tagMap,\n            operation,\n            rateDescription,\n            totalDescription\n        );\n        replay(StreamsMetricsImpl.class, streamsMetrics);\n\n        final Sensor sensor = TaskMetrics.droppedRecordsSensor(THREAD_ID, TASK_ID, streamsMetrics);\n\n        verify(StreamsMetricsImpl.class, streamsMetrics);\n        assertThat(sensor, is(expectedSensor));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetricsTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"M"}],"commitId":"69d507590efc0588a61214c35e0bb552744aae05","commitMessage":"@@@KAFKA-12924 Replace EasyMock and PowerMock with Mockito in streams metrics tests (#10850)\n\nReviewers: John Roesler <vvcephei@apache.org>.  Ismael Juma <ijuma@apache.org>","date":"2021-06-11 04:21:46","modifiedFileCount":"7","status":"M","submitter":"wycccccc"}]
