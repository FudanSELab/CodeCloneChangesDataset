[{"authorTime":"2021-08-17 03:04:29","codes":[{"authorDate":"2021-08-17 03:04:29","commitOrder":1,"curCode":"  public void testWriteSmallBuffer() throws IOException {\n\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET);\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"small-buffer\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\"hello\", read);\n  }\n","date":"2021-08-17 03:04:29","endLine":90,"groupId":"43949","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteSmallBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/e6/e7d66093e4096fc006544cc3b672db7e74527f.src","preCode":"  public void testWriteSmallBuffer() throws IOException {\n\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET);\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"small-buffer\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\"hello\", read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"B"},{"authorDate":"2021-08-17 03:04:29","commitOrder":1,"curCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET);\n    output.write(buffer);\n    output.flush();\n\n    buffer = \"some more\".getBytes(Charset.defaultCharset());\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"flush-large\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\n        \"Flushing a large frame of an S3OutputStream should not impact data written\",\n        content + \"some more\",\n        read);\n  }\n","date":"2021-08-17 03:04:29","endLine":159,"groupId":"43949","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testFlushLargeBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/e6/e7d66093e4096fc006544cc3b672db7e74527f.src","preCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET);\n    output.write(buffer);\n    output.flush();\n\n    buffer = \"some more\".getBytes(Charset.defaultCharset());\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"flush-large\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\n        \"Flushing a large frame of an S3OutputStream should not impact data written\",\n        content + \"some more\",\n        read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":138,"status":"B"}],"commitId":"1cb0850b70a7583501718ed635964f2f605d1742","commitMessage":"@@@SOLR-15089: Allow backup/restoration to Amazon's S3 blobstore (#120)\n\nSee solr/contrib/s3-repository/README.md for more information.\n\nCo-authored-by: Andy Throgmorton <athrogmorton@salesforce.com>\nCo-authored-by: Pierre Salagnac <psalagnac@salesforce.com>\nCo-authored-by: Houston Putman <houston@apache.org>","date":"2021-08-17 03:04:29","modifiedFileCount":"19","status":"B","submitter":"Andy Throgmorton"},{"authorTime":"2021-08-31 01:03:50","codes":[{"authorDate":"2021-08-31 01:03:50","commitOrder":2,"curCode":"  public void testWriteSmallBuffer() throws IOException {\n\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET);\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"small-buffer\"));\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\"hello\", read);\n  }\n","date":"2021-08-31 01:03:50","endLine":92,"groupId":"43949","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteSmallBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/36/323cc8318394e5920bb39dd4db3874fa4b48e4.src","preCode":"  public void testWriteSmallBuffer() throws IOException {\n\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET);\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"small-buffer\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\"hello\", read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":77,"status":"M"},{"authorDate":"2021-08-31 01:03:50","commitOrder":2,"curCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET);\n    output.write(buffer);\n    output.flush();\n\n    buffer = \"some more\".getBytes(Charset.defaultCharset());\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"flush-large\"));\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\n        \"Flushing a large frame of an S3OutputStream should not impact data written\",\n        content + \"some more\",\n        read);\n  }\n","date":"2021-08-31 01:03:50","endLine":161,"groupId":"43949","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testFlushLargeBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/36/323cc8318394e5920bb39dd4db3874fa4b48e4.src","preCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET);\n    output.write(buffer);\n    output.flush();\n\n    buffer = \"some more\".getBytes(Charset.defaultCharset());\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(BUCKET, \"flush-large\").getObjectContent();\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\n        \"Flushing a large frame of an S3OutputStream should not impact data written\",\n        content + \"some more\",\n        read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":140,"status":"M"}],"commitId":"51f4589c57ab8d0b0324219a043f386f794da11f","commitMessage":"@@@SOLR-15599: Upgrade AWS SDK from v1 to v2 (#271)\n\nAlso removed woodstox-core-asl dependency.  and replaced with com.fasterxml.woodstox:woodstox-core:6.2.4.  the newer version of the dependency.","date":"2021-08-31 01:03:50","modifiedFileCount":"10","status":"M","submitter":"Houston Putman"},{"authorTime":"2021-08-31 07:08:22","codes":[{"authorDate":"2021-08-31 07:08:22","commitOrder":3,"curCode":"  public void testWriteSmallBuffer() throws IOException {\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    try (S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET)) {\n      output.write(buffer);\n    }\n\n    \r\n    try (InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"small-buffer\"))) {\n      String read = IOUtils.toString(input, Charset.defaultCharset());\n      assertEquals(\"hello\", read);\n    }\n  }\n","date":"2021-09-01 02:15:21","endLine":90,"groupId":"101208","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testWriteSmallBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/3f/cd5a3d7819f4bcc57f5924abb3193210787eb2.src","preCode":"  public void testWriteSmallBuffer() throws IOException {\n\n    \r\n    byte[] buffer = \"hello\".getBytes(Charset.defaultCharset());\n    \r\n    assertTrue(buffer.length < S3OutputStream.PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"small-buffer\", BUCKET);\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"small-buffer\"));\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\"hello\", read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"M"},{"authorDate":"2021-08-31 07:08:22","commitOrder":3,"curCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    try (S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET)) {\n      output.write(buffer);\n      output.flush();\n\n      buffer = \"some more\".getBytes(Charset.defaultCharset());\n      output.write(buffer);\n    }\n\n    \r\n    try (InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"flush-large\"))) {\n      String read = IOUtils.toString(input, Charset.defaultCharset());\n      assertEquals(\n          \"Flushing a large frame of an S3OutputStream should not impact data written\",\n          content + \"some more\",\n          read);\n    }\n  }\n","date":"2021-09-01 02:15:21","endLine":161,"groupId":"101208","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"testFlushLargeBuffer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/3f/cd5a3d7819f4bcc57f5924abb3193210787eb2.src","preCode":"  public void testFlushLargeBuffer() throws IOException {\n    \r\n    String content = RandomStringUtils.randomAlphanumeric(S3OutputStream.MIN_PART_SIZE + 1024);\n    byte[] buffer = content.getBytes(Charset.defaultCharset());\n    assertTrue(buffer.length > S3OutputStream.MIN_PART_SIZE);\n\n    S3OutputStream output = new S3OutputStream(s3, \"flush-large\", BUCKET);\n    output.write(buffer);\n    output.flush();\n\n    buffer = \"some more\".getBytes(Charset.defaultCharset());\n    output.write(buffer);\n    output.close();\n\n    \r\n    InputStream input = s3.getObject(b -> b.bucket(BUCKET).key(\"flush-large\"));\n    String read = IOUtils.toString(input, Charset.defaultCharset());\n    assertEquals(\n        \"Flushing a large frame of an S3OutputStream should not impact data written\",\n        content + \"some more\",\n        read);\n  }\n","realPath":"solr/contrib/s3-repository/src/test/org/apache/solr/s3/S3OutputStreamTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":139,"status":"M"}],"commitId":"93be49b65bd5e0674ffb4bfefe9a4f77a7518138","commitMessage":"@@@SOLR-15599: Fix Security Policies for S3 Repository\n\n- Cleanup test code.\n","date":"2021-09-01 02:15:21","modifiedFileCount":"5","status":"M","submitter":"Houston Putman"}]
