[{"authorTime":"2017-08-01 15:49:57","codes":[{"authorDate":"2017-03-13 19:25:50","commitOrder":5,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      \r\n      \r\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2017-03-13 19:26:29","endLine":951,"groupId":"32267","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/bb/0ab9adeea9e179c57455b50d9f2305db1a83ce.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      \r\n      \r\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":835,"status":"NB"},{"authorDate":"2017-08-01 15:49:57","commitOrder":5,"curCode":"  protected int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2017-08-01 15:55:00","endLine":432,"groupId":"32267","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/74/9abdf804d224f7fba11e504871df9cb1a99c2f.src","preCode":"  protected int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":423,"status":"B"}],"commitId":"93ed4770ac82eb732c7409f82d02009e0fabe390","commitMessage":"@@@SOLR-9321: Remove deprecated methods of ClusterState\n","date":"2017-08-01 15:55:00","modifiedFileCount":"45","status":"M","submitter":"Cao Manh Dat"},{"authorTime":"2017-08-01 15:49:57","codes":[{"authorDate":"2018-01-29 16:55:28","commitOrder":6,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2018-01-29 16:55:28","endLine":935,"groupId":"32267","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/14/f0a7cb014d2575d18152a157c4776fe02789b3.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      \r\n      \r\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":822,"status":"M"},{"authorDate":"2017-08-01 15:49:57","commitOrder":6,"curCode":"  protected int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2017-08-01 15:55:00","endLine":432,"groupId":"32267","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/74/9abdf804d224f7fba11e504871df9cb1a99c2f.src","preCode":"  protected int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":423,"status":"N"}],"commitId":"27ef6530646a9af6f8fdf491afd80185bc4f7fee","commitMessage":"@@@SOLR-11702: Redesign current LIR implementation\n","date":"2018-01-29 16:55:28","modifiedFileCount":"16","status":"M","submitter":"Cao Manh Dat"},{"authorTime":"2018-04-04 04:41:57","codes":[{"authorDate":"2018-01-29 16:55:28","commitOrder":7,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2018-01-29 16:55:28","endLine":935,"groupId":"32267","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/14/f0a7cb014d2575d18152a157c4776fe02789b3.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":822,"status":"N"},{"authorDate":"2018-04-04 04:41:57","commitOrder":7,"curCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2018-04-04 04:41:57","endLine":529,"groupId":"32267","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/be/aeb2465e095d5299a6c3e1c95c6eec31c9db2c.src","preCode":"  protected int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"M"}],"commitId":"34b83ed86993d71ba3bb9ae58a3df8ce4351a045","commitMessage":"@@@SOLR-12176: Improve FORCELEADER to handle the case when a replica win the election but does not present in clusterstate\n","date":"2018-04-04 04:41:57","modifiedFileCount":"2","status":"M","submitter":"Cao Manh Dat"},{"authorTime":"2018-04-04 04:41:57","codes":[{"authorDate":"2018-11-30 01:58:18","commitOrder":8,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2018-11-30 01:58:51","endLine":1027,"groupId":"19367","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/72/dae068e912e3f177079bdc2edb20c5c53e9409.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":896,"status":"M"},{"authorDate":"2018-04-04 04:41:57","commitOrder":8,"curCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2018-04-04 04:41:57","endLine":529,"groupId":"32267","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/be/aeb2465e095d5299a6c3e1c95c6eec31c9db2c.src","preCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"N"}],"commitId":"75b183196798232aa6f2dcaaaab117f309119053","commitMessage":"@@@SOLR-12801: Make massive improvements to the tests.\n\nSOLR-12804: Remove static modifier from Overseer queue access.\n\nSOLR-12896: Introduce more checks for shutdown and closed to improve clean close and shutdown. (Partial)\n\nSOLR-12897: Introduce AlreadyClosedException to clean up silly close / shutdown logging. (Partial)\n\nSOLR-12898: Replace cluster state polling with ZkStateReader#waitFor. (Partial)\n\nSOLR-12923: The new AutoScaling tests are way too flaky and need special attention. (Partial)\n\nSOLR-12932: ant test (without badapples=false) should pass easily for developers. (Partial)\n\nSOLR-12933: Fix SolrCloud distributed commit.\n","date":"2018-11-30 01:58:51","modifiedFileCount":"339","status":"M","submitter":"markrmiller"},{"authorTime":"2018-04-04 04:41:57","codes":[{"authorDate":"2020-04-13 10:46:35","commitOrder":9,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2020-04-13 10:46:35","endLine":1088,"groupId":"19367","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/41/8aead206df58684b813f6d7d9833c7bc744f3f.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":957,"status":"M"},{"authorDate":"2018-04-04 04:41:57","commitOrder":9,"curCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2018-04-04 04:41:57","endLine":529,"groupId":"32267","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/be/aeb2465e095d5299a6c3e1c95c6eec31c9db2c.src","preCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"N"}],"commitId":"13f19f65559290a860df84fa1b5ac2db903b27ec","commitMessage":"@@@SOLR-9906: SolrjNamedThreadFactory is deprecated in favor of SolrNamedThreadFactory. DefaultSolrThreadFactory is removed from solr-core in favor of SolrNamedThreadFactory in solrj package and all solr-core classes now use SolrNamedThreadFactory\n","date":"2020-04-13 10:46:35","modifiedFileCount":"83","status":"M","submitter":"Shalin Shekhar Mangar"},{"authorTime":"2018-04-04 04:41:57","codes":[{"authorDate":"2020-05-01 07:50:31","commitOrder":10,"curCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Testing client (Fetch missing test): {}\", ((HttpSolrClient) client).getBaseURL());\n        log.info(\"Version at {} is: {}\"\n            , ((HttpSolrClient) client).getBaseURL(), getReplicaValue(client, 1, \"_version_\")); \r\n      }\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","date":"2020-05-01 07:50:31","endLine":1101,"groupId":"102866","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"delayedReorderingFetchesMissingUpdateFromLeaderTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/38/31100e885a3fb07d8a51c2e82d65328357ddf3.src","preCode":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    \r\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      \r\n      \r\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    \r\n    \r\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    \r\n    \r\n    \r\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); \r\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); \r\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        \r\n        \r\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { \r\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":969,"status":"M"},{"authorDate":"2018-04-04 04:41:57","commitOrder":10,"curCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","date":"2018-04-04 04:41:57","endLine":529,"groupId":"102866","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"getNumberOfActiveReplicas","params":"(ClusterStateclusterState@Stringcollection@StringsliceId)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/be/aeb2465e095d5299a6c3e1c95c6eec31c9db2c.src","preCode":"  private int getNumberOfActiveReplicas(ClusterState clusterState, String collection, String sliceId) {\n    int numActiveReplicas = 0;\n    \r\n    for (Replica rep : clusterState.getCollection(collection).getSlice(sliceId).getReplicas()) {\n      if (rep.getState().equals(State.ACTIVE)) {\n        numActiveReplicas++;\n      }\n    }\n    return numActiveReplicas;\n  }\n","realPath":"solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"N"}],"commitId":"9ae05e9b4f318dc0bbb352a6a65573614d0be26d","commitMessage":"@@@LUCENE-7788: fail precommit on unparameterised log messages and examine for wasted work/objects\n","date":"2020-05-01 07:50:31","modifiedFileCount":"170","status":"M","submitter":"Erick Erickson"}]
