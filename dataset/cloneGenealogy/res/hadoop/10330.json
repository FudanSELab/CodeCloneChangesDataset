[{"authorTime":"2018-06-29 05:28:23","codes":[{"authorDate":"2018-01-27 04:36:45","commitOrder":2,"curCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","date":"2018-01-27 04:36:45","endLine":825,"groupId":"18507","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDoubleTooManyFetchFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/43/571a9b824e21a78cc9dd0cdc7d9e09f085f2d7.src","preCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":758,"status":"NB"},{"authorDate":"2018-06-29 05:28:23","commitOrder":2,"curCode":"  public void testAppDiagnosticEventOnUnassignedTask() {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(\n        appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(\n        new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] { \"127.0.0.1\" });\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl = new MapTaskAttemptImpl(taskId, 1, eventHandler,\n        jobFile, 1, splits, jobConf, taListener,\n        new Token(), new Credentials(), SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,\n        \"Task got killed\"));\n    assertFalse(\n        \"InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task\",\n        eventHandler.internalError);\n    try {\n      taImpl.handle(new TaskAttemptEvent(attemptId,\n          TaskAttemptEventType.TA_KILL));\n      Assert.assertTrue(\"No exception on UNASSIGNED STATE KILL event\", true);\n    } catch (Exception e) {\n      Assert.assertFalse(\n          \"Exception not expected for UNASSIGNED STATE KILL event\", true);\n    }\n  }\n","date":"2018-06-29 05:28:23","endLine":911,"groupId":"18507","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testAppDiagnosticEventOnUnassignedTask","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/b1/b7b8f72dfdd0d191e57f4ead489e8638700ea7.src","preCode":"  public void testAppDiagnosticEventOnUnassignedTask() {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(\n        appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(\n        new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] { \"127.0.0.1\" });\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl = new MapTaskAttemptImpl(taskId, 1, eventHandler,\n        jobFile, 1, splits, jobConf, taListener,\n        new Token(), new Credentials(), SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,\n        \"Task got killed\"));\n    assertFalse(\n        \"InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task\",\n        eventHandler.internalError);\n    try {\n      taImpl.handle(new TaskAttemptEvent(attemptId,\n          TaskAttemptEventType.TA_KILL));\n      Assert.assertTrue(\"No exception on UNASSIGNED STATE KILL event\", true);\n    } catch (Exception e) {\n      Assert.assertFalse(\n          \"Exception not expected for UNASSIGNED STATE KILL event\", true);\n    }\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":856,"status":"B"}],"commitId":"c10452516804eed793e575dedcd1ee7758ec1f4c","commitMessage":"@@@Merge remote-tracking branch 'apache-commit/trunk' into HDDS-48\n","date":"2018-06-29 05:28:23","modifiedFileCount":"277","status":"M","submitter":"Bharat Viswanadham"},{"authorTime":"2018-06-29 05:28:23","codes":[{"authorDate":"2019-08-12 19:54:13","commitOrder":3,"curCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in SUCCEEDED state\")\n        .isEqualTo(TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in FAILED state\")\n        .isEqualTo(TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertThat(taImpl.getState())\n        .withFailMessage(\"Task attempt is not in FAILED state, still\")\n        .isEqualTo(TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","date":"2019-08-12 19:54:28","endLine":831,"groupId":"10330","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDoubleTooManyFetchFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/d0/9531c641c0ccbfce7d83a3d258ec03fe3c7e58.src","preCode":"  public void testDoubleTooManyFetchFailure() throws Exception {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId =\n      ApplicationAttemptId.newInstance(appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    TaskId reduceTaskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.REDUCE);\n    TaskAttemptId reduceTAId =\n        MRBuilderUtils.newTaskAttemptId(reduceTaskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] {\"127.0.0.1\"});\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl =\n      new MapTaskAttemptImpl(taskId, 1, eventHandler, jobFile, 1,\n          splits, jobConf, taListener,\n          new Token(), new Credentials(),\n          SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,\n        container, mock(Map.class)));\n    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId, 0));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_DONE));\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n    assertEquals(\"Task attempt is not in succeeded state\", taImpl.getState(),\n        TaskAttemptState.SUCCEEDED);\n    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,\n        reduceTAId, \"Host\"));\n    assertEquals(\"Task attempt is not in FAILED state\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));\n    assertEquals(\"Task attempt is not in FAILED state, still\", taImpl.getState(),\n        TaskAttemptState.FAILED);\n    assertFalse(\"InternalError occurred trying to handle TA_CONTAINER_CLEANED\",\n        eventHandler.internalError);\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":761,"status":"M"},{"authorDate":"2018-06-29 05:28:23","commitOrder":3,"curCode":"  public void testAppDiagnosticEventOnUnassignedTask() {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(\n        appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(\n        new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] { \"127.0.0.1\" });\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl = new MapTaskAttemptImpl(taskId, 1, eventHandler,\n        jobFile, 1, splits, jobConf, taListener,\n        new Token(), new Credentials(), SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,\n        \"Task got killed\"));\n    assertFalse(\n        \"InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task\",\n        eventHandler.internalError);\n    try {\n      taImpl.handle(new TaskAttemptEvent(attemptId,\n          TaskAttemptEventType.TA_KILL));\n      Assert.assertTrue(\"No exception on UNASSIGNED STATE KILL event\", true);\n    } catch (Exception e) {\n      Assert.assertFalse(\n          \"Exception not expected for UNASSIGNED STATE KILL event\", true);\n    }\n  }\n","date":"2018-06-29 05:28:23","endLine":911,"groupId":"10330","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testAppDiagnosticEventOnUnassignedTask","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-hadoop-10-0.7/blobInfo/CC_OUT/blobs/b1/b7b8f72dfdd0d191e57f4ead489e8638700ea7.src","preCode":"  public void testAppDiagnosticEventOnUnassignedTask() {\n    ApplicationId appId = ApplicationId.newInstance(1, 2);\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(\n        appId, 0);\n    JobId jobId = MRBuilderUtils.newJobId(appId, 1);\n    TaskId taskId = MRBuilderUtils.newTaskId(jobId, 1, TaskType.MAP);\n    TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(taskId, 0);\n    Path jobFile = mock(Path.class);\n\n    MockEventHandler eventHandler = new MockEventHandler();\n    TaskAttemptListener taListener = mock(TaskAttemptListener.class);\n    when(taListener.getAddress()).thenReturn(\n        new InetSocketAddress(\"localhost\", 0));\n\n    JobConf jobConf = new JobConf();\n    jobConf.setClass(\"fs.file.impl\", StubbedFS.class, FileSystem.class);\n    jobConf.setBoolean(\"fs.file.impl.disable.cache\", true);\n    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV, \"\");\n    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID, \"10\");\n\n    TaskSplitMetaInfo splits = mock(TaskSplitMetaInfo.class);\n    when(splits.getLocations()).thenReturn(new String[] { \"127.0.0.1\" });\n\n    AppContext appCtx = mock(AppContext.class);\n    ClusterInfo clusterInfo = mock(ClusterInfo.class);\n    Resource resource = mock(Resource.class);\n    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);\n    when(resource.getMemorySize()).thenReturn(1024L);\n    setupTaskAttemptFinishingMonitor(eventHandler, jobConf, appCtx);\n\n    TaskAttemptImpl taImpl = new MapTaskAttemptImpl(taskId, 1, eventHandler,\n        jobFile, 1, splits, jobConf, taListener,\n        new Token(), new Credentials(), SystemClock.getInstance(), appCtx);\n\n    NodeId nid = NodeId.newInstance(\"127.0.0.1\", 0);\n    ContainerId contId = ContainerId.newContainerId(appAttemptId, 3);\n    Container container = mock(Container.class);\n    when(container.getId()).thenReturn(contId);\n    when(container.getNodeId()).thenReturn(nid);\n    when(container.getNodeHttpAddress()).thenReturn(\"localhost:0\");\n    taImpl.handle(new TaskAttemptEvent(attemptId,\n        TaskAttemptEventType.TA_SCHEDULE));\n    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,\n        \"Task got killed\"));\n    assertFalse(\n        \"InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task\",\n        eventHandler.internalError);\n    try {\n      taImpl.handle(new TaskAttemptEvent(attemptId,\n          TaskAttemptEventType.TA_KILL));\n      Assert.assertTrue(\"No exception on UNASSIGNED STATE KILL event\", true);\n    } catch (Exception e) {\n      Assert.assertFalse(\n          \"Exception not expected for UNASSIGNED STATE KILL event\", true);\n    }\n  }\n","realPath":"hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TestTaskAttempt.java","repoName":"hadoop","snippetEndLine":0,"snippetStartLine":0,"startLine":856,"status":"N"}],"commitId":"ac6c4f0b290477017798491a4bd77fa9f107871c","commitMessage":"@@@MAPREDUCE-7197. Fix order of actual and expected expression in assert statements. Contributed by Adam Antal\n","date":"2019-08-12 19:54:28","modifiedFileCount":"75","status":"M","submitter":"Szilard Nemeth"}]
