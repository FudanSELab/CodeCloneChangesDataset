[{"authorTime":"2018-02-09 02:50:14","codes":[{"authorDate":"2017-08-29 19:33:33","commitOrder":5,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, nowInSeconds, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2017-08-29 19:33:50","endLine":313,"groupId":"7503","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/64/ac62751fe7a09fbd8ad799a2c664be0b0a712b.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, nowInSeconds, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"NB"},{"authorDate":"2018-02-09 02:50:14","commitOrder":5,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2018-02-09 02:50:14","endLine":514,"groupId":"24861","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/f6/46a2fd04acc35cf368c12400c6a02401275a4e.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":441,"status":"B"}],"commitId":"b2d20d4bb10e73935a97d6fbd848e4cb649c105c","commitMessage":"@@@Count deleted rows scanned during reads for tracing and warning tombstone thresholds.\n\nIf a row is read but is not live anymore (which happens with row level tombstones) it is not counted anywhere\nin the metrics nor reported in tracing. Row tombstones themselves are not reported anywhere.\nThe consequence is that some delete heavy workloads will show no tombstone read but endure severe\nperformance issues. This commit counts deleted rows as standard tombstone cells.\n\nPatch by Alexander Dejanovski; Reviewed by Jon Haddad for CASSANDRA-8527\n","date":"2018-02-09 02:50:14","modifiedFileCount":"3","status":"M","submitter":"Jon Haddad"},{"authorTime":"2018-02-14 21:23:02","codes":[{"authorDate":"2017-08-29 19:33:33","commitOrder":6,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, nowInSeconds, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2017-08-29 19:33:50","endLine":313,"groupId":"7503","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/64/ac62751fe7a09fbd8ad799a2c664be0b0a712b.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, nowInSeconds, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2018-02-14 21:23:02","commitOrder":6,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2018-02-14 21:25:31","endLine":541,"groupId":"24861","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/6a/82a5a7fa7401147c2d4c95c5938432ece14430.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":468,"status":"M"}],"commitId":"cf66b7ea2dfc296977a4fe2bdd56171ba937f48b","commitMessage":"@@@Merge branch 'cassandra-3.11' into trunk\n","date":"2018-02-14 21:25:31","modifiedFileCount":"1","status":"M","submitter":"Jason Brown"},{"authorTime":"2018-02-14 21:23:02","codes":[{"authorDate":"2018-07-27 02:11:17","commitOrder":7,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2018-08-23 21:14:07","endLine":345,"groupId":"7503","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/50/20b9531485e0427e0d3ee19730e6a15109cd96.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, nowInSeconds, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":218,"status":"M"},{"authorDate":"2018-02-14 21:23:02","commitOrder":7,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2018-02-14 21:25:31","endLine":541,"groupId":"24861","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/6a/82a5a7fa7401147c2d4c95c5938432ece14430.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":468,"status":"N"}],"commitId":"e225c88a65f2e8091f8ea6212c291416674882a1","commitMessage":"@@@Cell reconciliation should not depend on nowInSec\n\npatch by Benedict; reviewed by Aleksey for CASSANDRA-14592\n","date":"2018-08-23 21:14:07","modifiedFileCount":"28","status":"M","submitter":"Benedict Elliott Smith"},{"authorTime":"2018-02-14 21:23:02","codes":[{"authorDate":"2019-10-16 11:10:42","commitOrder":8,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                DeserializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2020-04-11 08:38:41","endLine":412,"groupId":"7503","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/e0/215b7fef96cbf2cb2d79c313bdaa1937b4ba9e.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                SerializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":285,"status":"M"},{"authorDate":"2018-02-14 21:23:02","commitOrder":8,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2018-02-14 21:25:31","endLine":541,"groupId":"24861","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/6a/82a5a7fa7401147c2d4c95c5938432ece14430.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":468,"status":"N"}],"commitId":"8576e769d13b3e887ea604074641fd4c42af5e8a","commitMessage":"@@@Minimize BTree iterator allocations\n\nPatch by Blake Eggleston; Reviewed by Benedict Elliott Smith for CASSANDRA-15389\n","date":"2020-04-11 08:38:41","modifiedFileCount":"35","status":"M","submitter":"Blake Eggleston"},{"authorTime":"2019-10-16 04:04:26","codes":[{"authorDate":"2019-10-16 04:04:26","commitOrder":9,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                DeserializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2020-09-14 23:32:44","endLine":426,"groupId":"7503","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/fc/2520ada2ae57141e50d48c73a19037fc5e6fde.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                DeserializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":299,"status":"M"},{"authorDate":"2019-10-16 04:04:26","commitOrder":9,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2020-09-14 23:32:44","endLine":622,"groupId":"24861","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/fc/2520ada2ae57141e50d48c73a19037fc5e6fde.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(ClusteringBound.BOTTOM, ClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":549,"status":"M"}],"commitId":"ccab496d2d37c86341d364dea6c27513fda27331","commitMessage":"@@@Add byte array backed cells\n\nPatch by Blake Eggleston; reviewed by Caleb Rackliffe and Marcus Eriksson for CASSANDRA-15393\n","date":"2020-09-14 23:32:44","modifiedFileCount":"278","status":"M","submitter":"Blake Eggleston"},{"authorTime":"2021-06-10 17:14:49","codes":[{"authorDate":"2021-06-10 17:14:49","commitOrder":10,"curCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata(), false).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                DeserializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","date":"2021-06-10 17:14:49","endLine":426,"groupId":"10462","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSinglePartitionGroupMerge","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/dc/d6331c3b6fb8b7960e78aa77b418d43c204949.src","preCode":"    public void testSinglePartitionGroupMerge() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF3);\n\n        String[][][] groups = new String[][][] {\n            new String[][] {\n                new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n            },\n            new String[][] {\n                new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n            },\n            new String[][] {\n                new String[] { \"-1\", \"key6\", \"aa\", \"a\" },\n                new String[] { \"-1\", \"key2\", \"bb\", \"b\" }\n            }\n        };\n\n        \r\n        \r\n        String[] expectedRows = new String[] { \"aa\", \"ff\", \"ee\", \"cc\", \"dd\", \"cc\", \"bb\"};\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                    .clustering(data[2])\n                    .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                    .build()\n                    .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(), ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter, DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                 UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                 DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                                                                                columnFilter,\n                                                                                buffer,\n                                                                                MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        \r\n        List<UnfilteredPartitionIterator> iterators = new ArrayList<>();\n\n        for (ByteBuffer buffer : buffers)\n        {\n            try (DataInputBuffer in = new DataInputBuffer(buffer, true))\n            {\n                iterators.add(UnfilteredPartitionIterators.serializerForIntraNode().deserialize(in,\n                                                                                                MessagingService.current_version,\n                                                                                                cfs.metadata(),\n                                                                                                columnFilter,\n                                                                                                DeserializationHelper.Flag.LOCAL));\n            }\n        }\n\n        UnfilteredPartitionIterators.MergeListener listener =\n            new UnfilteredPartitionIterators.MergeListener()\n            {\n                public UnfilteredRowIterators.MergeListener getRowMergeListener(DecoratedKey partitionKey, List<UnfilteredRowIterator> versions)\n                {\n                    return null;\n                }\n\n                public void close()\n                {\n\n                }\n            };\n\n        try (PartitionIterator partitionIterator = UnfilteredPartitionIterators.filter(UnfilteredPartitionIterators.merge(iterators, listener), nowInSeconds))\n        {\n\n            int i = 0;\n            int numPartitions = 0;\n            while (partitionIterator.hasNext())\n            {\n                numPartitions++;\n                try(RowIterator rowIterator = partitionIterator.next())\n                {\n                    while (rowIterator.hasNext())\n                    {\n                        Row row = rowIterator.next();\n                        assertEquals(\"col=\" + expectedRows[i++], row.clustering().toString(cfs.metadata()));\n                        \r\n                    }\n                }\n            }\n\n            assertEquals(5, numPartitions);\n            assertEquals(expectedRows.length, i);\n        }\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":299,"status":"M"},{"authorDate":"2021-06-10 17:14:49","commitOrder":10,"curCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata(), false).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","date":"2021-06-10 17:14:49","endLine":622,"groupId":"10462","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountWithNoDeletedRow","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cassandra-10-0.7/blobInfo/CC_OUT/blobs/dc/d6331c3b6fb8b7960e78aa77b418d43c204949.src","preCode":"    public void testCountWithNoDeletedRow() throws Exception\n    {\n        ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(CF5);\n\n        String[][][] groups = new String[][][] {\n                new String[][] {\n                        new String[] { \"1\", \"key1\", \"aa\", \"a\" }, \r\n                                                                 \r\n                        new String[] { \"1\", \"key2\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key3\", \"cc\", \"c\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key3\", \"dd\", \"d\" },\n                        new String[] { \"1\", \"key2\", \"ee\", \"e\" },\n                        new String[] { \"1\", \"key1\", \"ff\", \"f\" }\n                },\n                new String[][] {\n                        new String[] { \"1\", \"key6\", \"aa\", \"a\" },\n                        new String[] { \"1\", \"key5\", \"bb\", \"b\" },\n                        new String[] { \"1\", \"key4\", \"cc\", \"c\" }\n                }\n        };\n\n        List<ByteBuffer> buffers = new ArrayList<>(groups.length);\n        int nowInSeconds = FBUtilities.nowInSeconds();\n        ColumnFilter columnFilter = ColumnFilter.allRegularColumnsBuilder(cfs.metadata()).build();\n        RowFilter rowFilter = RowFilter.create();\n        Slice slice = Slice.make(BufferClusteringBound.BOTTOM, BufferClusteringBound.TOP);\n        ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter(\n                Slices.with(cfs.metadata().comparator, slice), false);\n\n        for (String[][] group : groups)\n        {\n            cfs.truncateBlocking();\n\n            List<SinglePartitionReadCommand> commands = new ArrayList<>(group.length);\n\n            for (String[] data : group)\n            {\n                if (data[0].equals(\"1\"))\n                {\n                    new RowUpdateBuilder(cfs.metadata(), 0, ByteBufferUtil.bytes(data[1]))\n                            .clustering(data[2])\n                            .add(data[3], ByteBufferUtil.bytes(\"blah\"))\n                            .build()\n                            .apply();\n                }\n                else\n                {\n                    RowUpdateBuilder.deleteRow(cfs.metadata(), FBUtilities.timestampMicros(),\n                            ByteBufferUtil.bytes(data[1]), data[2]).apply();\n                }\n                commands.add(SinglePartitionReadCommand.create(cfs.metadata(), nowInSeconds, columnFilter, rowFilter,\n                        DataLimits.NONE, Util.dk(data[1]), sliceFilter));\n            }\n\n            cfs.forceBlockingFlush();\n\n            ReadQuery query = new SinglePartitionReadCommand.Group(commands, DataLimits.NONE);\n\n            try (ReadExecutionController executionController = query.executionController();\n                    UnfilteredPartitionIterator iter = query.executeLocally(executionController);\n                    DataOutputBuffer buffer = new DataOutputBuffer())\n            {\n                UnfilteredPartitionIterators.serializerForIntraNode().serialize(iter,\n                        columnFilter,\n                        buffer,\n                        MessagingService.current_version);\n                buffers.add(buffer.buffer());\n            }\n        }\n\n        assertEquals(1, cfs.metric.tombstoneScannedHistogram.cf.getSnapshot().getMax());\n    }\n","realPath":"test/unit/org/apache/cassandra/db/ReadCommandTest.java","repoName":"cassandra","snippetEndLine":0,"snippetStartLine":0,"startLine":549,"status":"M"}],"commitId":"67cab368bc89da6cab0efbf019f666f6d647ebb1","commitMessage":"@@@Merge branch cassandra-4.0 into trunk\n","date":"2021-06-10 17:14:49","modifiedFileCount":"16","status":"M","submitter":"Benjamin Lerer"}]
