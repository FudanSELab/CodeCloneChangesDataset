[{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":722,"groupId":"17645","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c2/c4d2f8c76a74ab886b9c59bd9102f37974df19.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":637,"status":"B"},{"authorDate":"2018-08-31 00:56:26","commitOrder":1,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":613,"groupId":"17645","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/50/791c53dcebf8f47a1223a1cf59d98721187213.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":528,"status":"B"}],"commitId":"431d3d8497f9079857c3baa7ae7ab4cb44a22355","commitMessage":"@@@Rename io.druid to org.apache.druid. (#6266)\n\n* Rename io.druid to org.apache.druid.\n\n* Fix META-INF files and remove some benchmark results.\n\n* MonitorsConfig update for metrics package migration.\n\n* Reorder some dimensions in inner queries for some reason.\n\n* Fix protobuf tests.\n","date":"2018-08-31 00:56:26","modifiedFileCount":"5","status":"B","submitter":"Gian Merlino"},{"authorTime":"2018-08-31 00:56:26","codes":[{"authorDate":"2018-10-29 20:02:43","commitOrder":2,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-10-29 20:02:43","endLine":723,"groupId":"17645","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/46/6c478707cae5d2e5187be4c0276757689c6b1d.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), Maps.newHashMap()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":638,"status":"M"},{"authorDate":"2018-08-31 00:56:26","commitOrder":2,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2018-08-31 00:56:26","endLine":613,"groupId":"17645","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/50/791c53dcebf8f47a1223a1cf59d98721187213.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":528,"status":"N"}],"commitId":"676f5e6d7f184101b8763e4249b18b237bbe0ec7","commitMessage":"@@@Prohibit some guava collection APIs and use JDK collection APIs directly (#6511)\n\n* Prohibit some guava collection APIs and use JDK APIs directly\n\n* reset files that changed by accident\n\n* sort codestyle/druid-forbidden-apis.txt alphabetically\n","date":"2018-10-29 20:02:43","modifiedFileCount":"427","status":"M","submitter":"QiuMM"},{"authorTime":"2019-02-05 01:18:12","codes":[{"authorDate":"2019-02-05 01:18:12","commitOrder":3,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2019-02-05 01:18:12","endLine":723,"groupId":"17645","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/22/e3e6838297c3f78fc5b098fb88ba34cdb26eec.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":638,"status":"M"},{"authorDate":"2019-02-05 01:18:12","commitOrder":3,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","date":"2019-02-05 01:18:12","endLine":614,"groupId":"17645","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/69/857f5c5ecc95a70b49ad506972034c1550de29.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":529,"status":"M"}],"commitId":"0e926e865276f892ddc5b62685d331b822104022","commitMessage":"@@@Prohibit assigning concurrent maps into Map-typed variables and fields and fix a race condition in CoordinatorRuleManager (#6898)\n\n* Prohibit assigning concurrent maps into Map-types variables and fields; Fix a race condition in CoordinatorRuleManager; improve logic in DirectDruidClient and ResourcePool\n\n* Enforce that if compute().  computeIfAbsent().  computeIfPresent() or merge() is called on a ConcurrentHashMap.  it's stored in a ConcurrentHashMap-typed variable.  not ConcurrentMap; add comments explaining get()-before-computeIfAbsent() optimization; refactor Counters; fix a race condition in Intialization.java\n\n* Remove unnecessary comment\n\n* Checkstyle\n\n* Fix getFromExtensions()\n\n* Add a reference to the comment about guarded computeIfAbsent() optimization; IdentityHashMap optimization\n\n* Fix UriCacheGeneratorTest\n\n* Workaround issue with MaterializedViewQueryQueryToolChest\n\n* Strengthen Appenderator's contract regarding concurrency\n","date":"2019-02-05 01:18:12","modifiedFileCount":"101","status":"M","submitter":"Roman Leventov"},{"authorTime":"2019-03-15 05:28:33","codes":[{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":722,"groupId":"17645","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/74/b3070ef5651c6429aa2a7e5aeb364e18ac50da.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":637,"status":"M"},{"authorDate":"2019-03-15 05:28:33","commitOrder":4,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-03-15 05:28:33","endLine":613,"groupId":"17645","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/e1/43caa10981038b772e2285a40b4ebb4ac237f7.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw Throwables.propagate(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":528,"status":"M"}],"commitId":"7ada1c49f9735a37808f3ed7656d93ae88b8b925","commitMessage":"@@@Prohibit Throwables.propagate() (#7121)\n\n* Throw caught exception.\n\n* Throw caught exceptions.\n\n* Related checkstyle rule is added to prevent further bugs.\n\n* RuntimeException() is used instead of Throwables.propagate().\n\n* Missing import is added.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* Throwables are propogated if possible.\n\n* * Checkstyle definition is improved.\n* Throwables.propagate() usages are removed.\n\n* Checkstyle pattern is changed for only scanning \"Throwables.propagate(\" instead of checking lookbehind.\n\n* Throwable is kept before firing a Runtime Exception.\n\n* Fix unused assignments.\n","date":"2019-03-15 05:28:33","modifiedFileCount":"228","status":"M","submitter":"Furkan KAMACI"},{"authorTime":"2019-07-24 23:29:03","codes":[{"authorDate":"2019-07-24 23:29:03","commitOrder":5,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-07-24 23:29:03","endLine":721,"groupId":"17645","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/71/425369c093dd756792179b595324c8c56a3279.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), new HashMap<>()));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":636,"status":"M"},{"authorDate":"2019-07-24 23:29:03","commitOrder":5,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2019-07-24 23:29:03","endLine":610,"groupId":"17645","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/bf/29d87b0418deb5d61f12982661f1bc6853a9b0.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      HashMap<String, Object> context = new HashMap<String, Object>();\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query), context));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":526,"status":"M"}],"commitId":"799d20249fe6333ea86b020f6d09c91fa4d3f998","commitMessage":"@@@Response context refactoring (#8110)\n\n* Response context refactoring\n\n* Serialization/Deserialization of ResponseContext\n\n* Added java doc comments\n\n* Renamed vars related to ResponseContext\n\n* Renamed empty() methods to createEmpty()\n\n* Fixed ResponseContext usage\n\n* Renamed multiple ResponseContext static fields\n\n* Added PublicApi annotations\n\n* Renamed QueryResponseContext class to ResourceIOReaderWriter\n\n* Moved the protected method below public static constants\n\n* Added createEmpty method to ResponseContext with DefaultResponseContext creation\n\n* Fixed inspection error\n\n* Added comments to the ResponseContext length limit and ResponseContext\nhttp header name\n\n* Added a comment of possible future refactoring\n\n* Removed .gitignore file of indexing-service\n\n* Removed a never-used method\n\n* VisibleForTesting method reducing boilerplate\n\nCo-Authored-By: Clint Wylie <cjwylie@gmail.com>\n\n* Reduced boilerplate\n\n* Renamed the method serialize to serializeWith\n\n* Removed unused import\n\n* Fixed incorrectly refactored test method\n\n* Added comments for ResponseContext keys\n\n* Fixed incorrectly refactored test method\n\n* Fixed IntervalChunkingQueryRunnerTest mocks\n","date":"2019-07-24 23:29:03","modifiedFileCount":"142","status":"M","submitter":"Eugene Sevastianov"},{"authorTime":"2020-01-20 09:14:23","codes":[{"authorDate":"2020-01-20 09:14:23","commitOrder":6,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-01-20 09:14:23","endLine":718,"groupId":"105930","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/3a/b78fc986ac467a2d4f3202f67dfefcbdde22f9.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 17L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 29L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 13L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 91L)\n                            .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                            .put(\"rows\", 1L)\n                            .put(\"val\", 47L)\n                            .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":634,"status":"M"},{"authorDate":"2020-01-20 09:14:23","commitOrder":6,"curCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","date":"2020-01-20 09:14:23","endLine":608,"groupId":"105930","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testSpatialQueryMorePoints","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/93/28904fc7bf75fd97bfcc78c6268dbc99701e7f.src","preCode":"  public void testSpatialQueryMorePoints()\n  {\n    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n                                  .dataSource(\"test\")\n                                  .granularity(Granularities.DAY)\n                                  .intervals(Collections.singletonList(Intervals.of(\"2013-01-01/2013-01-07\")))\n                                  .filters(\n                                      new SpatialDimFilter(\n                                          \"dim.geo\",\n                                          new RectangularBound(new float[]{0.0f, 0.0f}, new float[]{9.0f, 9.0f})\n                                      )\n                                  )\n                                  .aggregators(\n                                      Arrays.asList(\n                                          new CountAggregatorFactory(\"rows\"),\n                                          new LongSumAggregatorFactory(\"val\", \"val\")\n                                      )\n                                  )\n                                  .build();\n\n    List<Result<TimeseriesResultValue>> expectedResults = Arrays.asList(\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-01T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 17L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-02T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 29L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-03T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 13L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-04T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 91L)\n                    .build()\n            )\n        ),\n        new Result<TimeseriesResultValue>(\n            DateTimes.of(\"2013-01-05T00:00:00.000Z\"),\n            new TimeseriesResultValue(\n                ImmutableMap.<String, Object>builder()\n                    .put(\"rows\", 1L)\n                    .put(\"val\", 47L)\n                    .build()\n            )\n        )\n    );\n    try {\n      TimeseriesQueryRunnerFactory factory = new TimeseriesQueryRunnerFactory(\n          new TimeseriesQueryQueryToolChest(\n              QueryRunnerTestHelper.noopIntervalChunkingQueryRunnerDecorator()),\n          new TimeseriesQueryEngine(),\n          QueryRunnerTestHelper.NOOP_QUERYWATCHER\n      );\n\n      QueryRunner runner = new FinalizeResultsQueryRunner(\n          factory.createRunner(segment),\n          factory.getToolchest()\n      );\n      TestHelper.assertExpectedResults(expectedResults, runner.run(QueryPlus.wrap(query)));\n    }\n    catch (Exception e) {\n      throw new RuntimeException(e);\n    }\n  }\n","realPath":"processing/src/test/java/org/apache/druid/segment/filter/SpatialFilterBonusTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":525,"status":"M"}],"commitId":"d21054f7c5f72f9db1ecfb72b46ee866876f1e4b","commitMessage":"@@@Remove the deprecated interval-chunking stuff. (#9216)\n\n* Remove the deprecated interval-chunking stuff.\n\nSee https://github.com/apache/druid/pull/6591.  https://github.com/apache/druid/pull/4004#issuecomment-284171911 for details.\n\n* Remove unused import.\n\n* Remove chunkInterval too.\n","date":"2020-01-20 09:14:23","modifiedFileCount":"65","status":"M","submitter":"Gian Merlino"}]
