[{"authorTime":"2020-07-02 13:20:53","codes":[{"authorDate":"2020-03-04 12:51:06","commitOrder":6,"curCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(S3_CLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(S3_CLIENT);\n\n    S3InputSource inputSource = new S3InputSource(\n        SERVICE,\n        SERVER_SIDE_ENCRYPTING_AMAZON_S3_BUILDER,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(S3_CLIENT);\n  }\n","date":"2020-03-04 12:51:06","endLine":530,"groupId":"20131","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/12/2f4fd6a56b242c5a558bc20248a2ffa62af036.src","preCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(S3_CLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(S3_CLIENT);\n\n    S3InputSource inputSource = new S3InputSource(\n        SERVICE,\n        SERVER_SIDE_ENCRYPTING_AMAZON_S3_BUILDER,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(S3_CLIENT);\n  }\n","realPath":"extensions-core/s3-extensions/src/test/java/org/apache/druid/data/input/s3/S3InputSourceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":489,"status":"NB"},{"authorDate":"2020-07-02 13:20:53","commitOrder":6,"curCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(OSSCLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(OSSCLIENT);\n\n    OssInputSource inputSource = new OssInputSource(\n        OSSCLIENT,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(OSSCLIENT);\n  }\n","date":"2020-07-02 13:20:53","endLine":475,"groupId":"20131","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/2b/d9d5816acc27b1dac76a0fa8fc2948907b82e7.src","preCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(OSSCLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(OSSCLIENT);\n\n    OssInputSource inputSource = new OssInputSource(\n        OSSCLIENT,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(OSSCLIENT);\n  }\n","realPath":"extensions-contrib/aliyun-oss-extensions/src/test/java/org/apache/druid/data/input/aliyun/OssInputSourceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":435,"status":"B"}],"commitId":"60c6bd5b4c44f28f5dbff48e70c6138ce35204b6","commitMessage":"@@@support Aliyun OSS service as deep storage (#9898)\n\n* init commit.  all tests passed\n\n* fix format\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* data stored successfully\n\n* modify config path\n\n* add doc\n\n* add aliyun-oss extension to project\n\n* remove descriptor deletion code to avoid warning message output by aliyun client\n\n* fix warnings reported by lgtm-com\n\n* fix ci warnings\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* fix errors reported by intellj inspection check\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* fix doc spelling check\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* fix dependency warnings reported by ci\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* fix warnings reported by CI\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* add package configuration to support showing extension info\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* add IT test cases and fix bugs\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* 1. code review comments adopted\n2. change schema from 'aliyun-oss' to 'oss'\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* add license info\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* fix doc\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* exclude execution of IT testcases of OSS extension from CI\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>\n\n* put the extensions under contrib group and add to distribution\n\n* fix names in test cases\n\n* add unit test to cover OssInputSource\n\n* fix names in test cases\n\n* fix dependency problem reported by CI\n\nSigned-off-by: frank chen <frank.chen021@outlook.com>","date":"2020-07-02 13:20:53","modifiedFileCount":"1","status":"M","submitter":"frank chen"},{"authorTime":"2021-03-26 01:32:21","codes":[{"authorDate":"2021-03-26 01:32:21","commitOrder":7,"curCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(S3_CLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(S3_CLIENT);\n\n    S3InputSource inputSource = new S3InputSource(\n        SERVICE,\n        SERVER_SIDE_ENCRYPTING_AMAZON_S3_BUILDER,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ColumnsFilter.all()\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(S3_CLIENT);\n  }\n","date":"2021-03-26 01:32:21","endLine":532,"groupId":"102885","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/41/a5f8a36c8b9dd24527a7179bf2bbb1c66e2b32.src","preCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(S3_CLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(S3_CLIENT);\n\n    S3InputSource inputSource = new S3InputSource(\n        SERVICE,\n        SERVER_SIDE_ENCRYPTING_AMAZON_S3_BUILDER,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(S3_CLIENT);\n  }\n","realPath":"extensions-core/s3-extensions/src/test/java/org/apache/druid/data/input/s3/S3InputSourceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":491,"status":"M"},{"authorDate":"2021-03-26 01:32:21","commitOrder":7,"curCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(OSSCLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(OSSCLIENT);\n\n    OssInputSource inputSource = new OssInputSource(\n        OSSCLIENT,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ColumnsFilter.all()\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(OSSCLIENT);\n  }\n","date":"2021-03-26 01:32:21","endLine":478,"groupId":"102885","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testReader","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b7/e95402e234caae024d7d0308288fe7b83fc5f0.src","preCode":"  public void testReader() throws IOException\n  {\n    EasyMock.reset(OSSCLIENT);\n    expectListObjects(PREFIXES.get(0), ImmutableList.of(EXPECTED_URIS.get(0)), CONTENT);\n    expectListObjects(EXPECTED_URIS.get(1), ImmutableList.of(EXPECTED_URIS.get(1)), CONTENT);\n    expectGetObject(EXPECTED_URIS.get(0));\n    expectGetObject(EXPECTED_URIS.get(1));\n    EasyMock.replay(OSSCLIENT);\n\n    OssInputSource inputSource = new OssInputSource(\n        OSSCLIENT,\n        INPUT_DATA_CONFIG,\n        null,\n        ImmutableList.of(PREFIXES.get(0), EXPECTED_URIS.get(1)),\n        null,\n        null\n    );\n\n    InputRowSchema someSchema = new InputRowSchema(\n        new TimestampSpec(\"time\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"dim1\", \"dim2\"))),\n        ImmutableList.of(\"count\")\n    );\n\n    InputSourceReader reader = inputSource.reader(\n        someSchema,\n        new CsvInputFormat(ImmutableList.of(\"time\", \"dim1\", \"dim2\"), \"|\", false, null, 0),\n        temporaryFolder.newFolder()\n    );\n\n    CloseableIterator<InputRow> iterator = reader.read();\n\n    while (iterator.hasNext()) {\n      InputRow nextRow = iterator.next();\n      Assert.assertEquals(NOW, nextRow.getTimestamp());\n      Assert.assertEquals(\"hello\", nextRow.getDimension(\"dim1\").get(0));\n      Assert.assertEquals(\"world\", nextRow.getDimension(\"dim2\").get(0));\n    }\n\n    EasyMock.verify(OSSCLIENT);\n  }\n","realPath":"extensions-contrib/aliyun-oss-extensions/src/test/java/org/apache/druid/data/input/aliyun/OssInputSourceTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":438,"status":"M"}],"commitId":"bf20f9e9798417c9293a195690b6adcb48f44d3f","commitMessage":"@@@DruidInputSource: Fix issues in column projection.  timestamp handling. (#10267)\n\n* DruidInputSource: Fix issues in column projection.  timestamp handling.\n\nDruidInputSource.  DruidSegmentReader changes:\n\n1) Remove \"dimensions\" and \"metrics\". They are not necessary.  because we\n   can compute which columns we need to read based on what is going to\n   be used by the timestamp.  transform.  dimensions.  and metrics.\n2) Start using ColumnsFilter (see below) to decide which columns we need\n   to read.\n3) Actually respect the \"timestampSpec\". Previously.  it was ignored.  and\n   the timestamp of the returned InputRows was set to the `__time` column\n   of the input datasource.\n\n(1) and (2) together fix a bug in which the DruidInputSource would not\nproperly read columns that are used as inputs to a transformSpec.\n\n(3) fixes a bug where the timestampSpec would be ignored if you attempted\nto set the column to something other than `__time`.\n\n(1) and (3) are breaking changes.\n\nWeb console changes:\n\n1) Remove \"Dimensions\" and \"Metrics\" from the Druid input source.\n2) Set timestampSpec to `{\"column\": \"__time\".  \"format\": \"millis\"}` for\n   compatibility with the new behavior.\n\nOther changes:\n\n1) Add ColumnsFilter.  a new class that allows input readers to determine\n   which columns they need to read. Currently.  it's only used by the\n   DruidInputSource.  but it could be used by other columnar input sources\n   in the future.\n2) Add a ColumnsFilter to InputRowSchema.\n3) Remove the metric names from InputRowSchema (they were unused).\n4) Add InputRowSchemas.fromDataSchema method that computes the proper\n   ColumnsFilter for given timestamp.  dimensions.  transform.  and metrics.\n5) Add \"getRequiredColumns\" method to TransformSpec to support the above.\n\n* Various fixups.\n\n* Uncomment incorrectly commented lines.\n\n* Move TransformSpecTest to the proper module.\n\n* Add druid.indexer.task.ignoreTimestampSpecForDruidInputSource setting.\n\n* Fix.\n\n* Fix build.\n\n* Checkstyle.\n\n* Misc fixes.\n\n* Fix test.\n\n* Move config.\n\n* Fix imports.\n\n* Fixup.\n\n* Fix ShuffleResourceTest.\n\n* Add import.\n\n* Smarter exclusions.\n\n* Fixes based on tests.\n\nAlso.  add TIME_COLUMN constant in the web console.\n\n* Adjustments for tests.\n\n* Reorder test data.\n\n* Update docs.\n\n* Update docs to say Druid 0.22.0 instead of 0.21.0.\n\n* Fix test.\n\n* Fix ITAutoCompactionTest.\n\n* Changes from review & from merging.","date":"2021-03-26 01:32:21","modifiedFileCount":"60","status":"M","submitter":"Gian Merlino"}]
