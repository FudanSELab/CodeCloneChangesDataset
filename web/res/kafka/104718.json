[{"authorTime":"2016-12-02 07:01:09","codes":[{"authorDate":"2016-12-02 07:01:09","commitOrder":5,"curCode":"    public void testCommit() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        \r\n        Capture<Collection<SinkRecord>> capturedRecords\n                = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, null, null, 0, true);\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        \r\n        assertEquals(0, workerTask.commitFailures());\n        workerTask.stop();\n        workerTask.close();\n\n        assertEquals(2, capturedRecords.getValues().size());\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-12-02 07:01:09","endLine":207,"groupId":"5277","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8f/a62b668a3d49ee8d8e52901d464372b8f5a7ca.src","preCode":"    public void testCommit() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        \r\n        Capture<Collection<SinkRecord>> capturedRecords\n                = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, null, null, 0, true);\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        \r\n        assertEquals(0, workerTask.commitFailures());\n        workerTask.stop();\n        workerTask.close();\n\n        assertEquals(2, capturedRecords.getValues().size());\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskThreadedTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":177,"status":"MB"},{"authorDate":"2016-12-02 07:01:09","commitOrder":5,"curCode":"    public void testCommitFailure() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        Capture<Collection<SinkRecord>> capturedRecords = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, new RuntimeException(), null, 0, true);\n        \r\n        \r\n        consumer.seek(TOPIC_PARTITION, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION2, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION3, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        assertEquals(1, workerTask.commitFailures());\n        assertEquals(false, Whitebox.getInternalState(workerTask, \"committing\"));\n        workerTask.stop();\n        workerTask.close();\n\n        PowerMock.verifyAll();\n    }\n","date":"2016-12-02 07:01:09","endLine":244,"groupId":"3441","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCommitFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/8f/a62b668a3d49ee8d8e52901d464372b8f5a7ca.src","preCode":"    public void testCommitFailure() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        Capture<Collection<SinkRecord>> capturedRecords = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, new RuntimeException(), null, 0, true);\n        \r\n        \r\n        consumer.seek(TOPIC_PARTITION, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION2, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION3, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        assertEquals(1, workerTask.commitFailures());\n        assertEquals(false, Whitebox.getInternalState(workerTask, \"committing\"));\n        workerTask.stop();\n        workerTask.close();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskThreadedTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":210,"status":"B"}],"commitId":"b45a67ede9021985c8df87c633b225231092c0c9","commitMessage":"@@@KAFKA-4161: KIP-89: Allow sink connectors to decouple flush and offset commit\n\nAuthor: Shikhar Bhushan <shikhar@confluent.io>\n\nReviewers: Ewen Cheslack-Postava <ewen@confluent.io>\n\nCloses #2139 from shikhar/kafka-4161-deux\n","date":"2016-12-02 07:01:09","modifiedFileCount":"6","status":"M","submitter":"Shikhar Bhushan"},{"authorTime":"2020-01-30 13:54:21","codes":[{"authorDate":"2020-01-30 13:54:21","commitOrder":6,"curCode":"    public void testCommit() throws Exception {\n        expectInitializeTask();\n        expectTaskGetTopic(true);\n        expectPollInitialAssignment();\n\n        \r\n        Capture<Collection<SinkRecord>> capturedRecords\n                = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, null, null, 0, true);\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        \r\n        assertEquals(0, workerTask.commitFailures());\n        workerTask.stop();\n        workerTask.close();\n\n        assertEquals(2, capturedRecords.getValues().size());\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-01-30 13:54:21","endLine":230,"groupId":"104718","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommit","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/be/2584a9235b7cc044ab34f2e367b0138241e160.src","preCode":"    public void testCommit() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        \r\n        Capture<Collection<SinkRecord>> capturedRecords\n                = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, null, null, 0, true);\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        \r\n        assertEquals(0, workerTask.commitFailures());\n        workerTask.stop();\n        workerTask.close();\n\n        assertEquals(2, capturedRecords.getValues().size());\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskThreadedTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":199,"status":"M"},{"authorDate":"2020-01-30 13:54:21","commitOrder":6,"curCode":"    public void testCommitFailure() throws Exception {\n        expectInitializeTask();\n        expectTaskGetTopic(true);\n        expectPollInitialAssignment();\n\n        Capture<Collection<SinkRecord>> capturedRecords = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, new RuntimeException(), null, 0, true);\n        \r\n        \r\n        consumer.seek(TOPIC_PARTITION, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION2, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION3, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        assertEquals(1, workerTask.commitFailures());\n        assertEquals(false, Whitebox.getInternalState(workerTask, \"committing\"));\n        workerTask.stop();\n        workerTask.close();\n\n        PowerMock.verifyAll();\n    }\n","date":"2020-01-30 13:54:21","endLine":268,"groupId":"104718","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCommitFailure","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/be/2584a9235b7cc044ab34f2e367b0138241e160.src","preCode":"    public void testCommitFailure() throws Exception {\n        expectInitializeTask();\n        expectPollInitialAssignment();\n\n        Capture<Collection<SinkRecord>> capturedRecords = expectPolls(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_DEFAULT);\n        expectOffsetCommit(1L, new RuntimeException(), null, 0, true);\n        \r\n        \r\n        consumer.seek(TOPIC_PARTITION, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION2, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        consumer.seek(TOPIC_PARTITION3, FIRST_OFFSET);\n        PowerMock.expectLastCall();\n        expectStopTask();\n\n        PowerMock.replayAll();\n\n        workerTask.initialize(TASK_CONFIG);\n        workerTask.initializeAndStart();\n\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n        \r\n        workerTask.iteration();\n\n        assertEquals(1, workerTask.commitFailures());\n        assertEquals(false, Whitebox.getInternalState(workerTask, \"committing\"));\n        workerTask.stop();\n        workerTask.close();\n\n        PowerMock.verifyAll();\n    }\n","realPath":"connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerSinkTaskThreadedTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":233,"status":"M"}],"commitId":"7746301c2643e0037bff3bcb84c41d512937e4c9","commitMessage":"@@@KAFKA-9422: Track the set of topics a connector is using (KIP-558) (#8017)\n\nThis feature corresponds to KIP-558 and extends how the internal status topic (set via `status.storage.topic` distributed worker config) is used to include information that allows Kafka Connect to keep track which topics a connector is using.\n\nThe set of topics a connector is actively using.  is exposed via a new endpoint that is added to the REST API of Connect workers.\n* A `GET /connectors/{name}/topics` request will return the set of topics that have been recorded as active since a connector started or since the set of topics was reset for this connector.\n\nAn additional endpoints allows users to reset the set of active topics for a connector via the second endpoint that this feature is adding:\n* A `PUT /connectors/{name}/topics/reset` request clears the set of active topics. An operator may enable or disable this feature by setting `topic.tracking.enable` (true by default).\n\nThe `topic.tracking.enable` worker config property (true by default) allows an operator to enable/disable the entire feature. Or if the feature is enabled.  the `topic.tracking.allow.reset` worker config property (true by default) allows an operator to control whether reset requests submitted to the Connect REST API are allowed.\n\nAuthor: Konstantine Karantasis <konstantine@confluent.io>\nReviewer: Randall Hauch <rhauch@gmail.com>","date":"2020-01-30 13:54:21","modifiedFileCount":"17","status":"M","submitter":"Konstantine Karantasis"}]
