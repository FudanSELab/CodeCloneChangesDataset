[{"authorTime":"2018-08-17 14:03:27","codes":[{"authorDate":"2018-08-17 14:03:27","commitOrder":2,"curCode":"  public void testAdds() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 500;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n\n    Assert.assertEquals(\"There have been no updates yet, so there shouldn't have been any commits\", 0,\n        hardCommitTracker.getCommitCount());\n\n    long tlogSizePreUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertEquals(\"There have been no updates yet, so tlog should be empty\", 0, tlogSizePreUpdates);\n\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\", hardCommitTracker.getCommitCount() > 0);\n    long tlogSizePostUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostUpdates < maxFileSizeBound);\n  }\n","date":"2018-08-17 14:05:21","endLine":99,"groupId":"60273","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testAdds","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/33/fd7de6d042aa9ea3955d4e7a3c73c27ef93234.src","preCode":"  public void testAdds() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 500;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n\n    Assert.assertEquals(\"There have been no updates yet, so there shouldn't have been any commits\", 0,\n        hardCommitTracker.getCommitCount());\n\n    long tlogSizePreUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertEquals(\"There have been no updates yet, so tlog should be empty\", 0, tlogSizePreUpdates);\n\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\", hardCommitTracker.getCommitCount() > 0);\n    long tlogSizePostUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostUpdates < maxFileSizeBound);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"B"},{"authorDate":"2018-08-17 14:03:27","commitOrder":2,"curCode":"  public void testRedundantDeletes() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 150;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n    waitForCommit(1000);\n\n    \r\n    int commitCountPreDeletes = hardCommitTracker.getCommitCount();\n\n    \r\n    int numDeletesToSend = 500;\n    int docIdToDelete = 100;\n\n    SolrQueryRequestBase batchSingleDeleteRequest = new SolrQueryRequestBase(core, new MapSolrParams(new HashMap<>())) {};\n    List<String> docs = new ArrayList<>();\n    for (int i = 0; i < numDeletesToSend; i++) {\n      docs.add(delI(Integer.toString(docIdToDelete)));\n    }\n    batchSingleDeleteRequest.setContentStreams(toContentStreams(docs));\n\n    updateRequestHandler.handleRequest(batchSingleDeleteRequest, updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\",\n        hardCommitTracker.getCommitCount() > commitCountPreDeletes);\n    long tlogSizePostDeletes = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostDeletes < maxFileSizeBound);\n  }\n","date":"2018-08-17 14:05:21","endLine":137,"groupId":"60271","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRedundantDeletes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/33/fd7de6d042aa9ea3955d4e7a3c73c27ef93234.src","preCode":"  public void testRedundantDeletes() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 150;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n    waitForCommit(1000);\n\n    \r\n    int commitCountPreDeletes = hardCommitTracker.getCommitCount();\n\n    \r\n    int numDeletesToSend = 500;\n    int docIdToDelete = 100;\n\n    SolrQueryRequestBase batchSingleDeleteRequest = new SolrQueryRequestBase(core, new MapSolrParams(new HashMap<>())) {};\n    List<String> docs = new ArrayList<>();\n    for (int i = 0; i < numDeletesToSend; i++) {\n      docs.add(delI(Integer.toString(docIdToDelete)));\n    }\n    batchSingleDeleteRequest.setContentStreams(toContentStreams(docs));\n\n    updateRequestHandler.handleRequest(batchSingleDeleteRequest, updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\",\n        hardCommitTracker.getCommitCount() > commitCountPreDeletes);\n    long tlogSizePostDeletes = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostDeletes < maxFileSizeBound);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"MB"}],"commitId":"4309ae6f9fdb70d780ee08bfc32ec3a36e68389a","commitMessage":"@@@SOLR-12475: Fix failing MaxSizeAutoCommitTest\n","date":"2018-08-17 14:05:21","modifiedFileCount":"2","status":"M","submitter":"Anshum Gupta"},{"authorTime":"2018-12-05 01:44:05","codes":[{"authorDate":"2018-12-05 01:44:05","commitOrder":3,"curCode":"  public void testAdds() throws Exception {\n\n    Assert.assertEquals(\"There have been no updates yet, so there shouldn't have been any commits\", 0,\n                        hardCommitTracker.getCommitCount());\n\n    long tlogSizePreUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertEquals(\"There have been no updates yet, so tlog should be empty\", 0, tlogSizePreUpdates);\n\n    \r\n    int numDocsToAdd = 500;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    \n    monitor.doStuffAndExpectAtLeastOneCommit(hardCommitTracker, updateHandler, () -> {\n        updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n      });\n  }\n","date":"2018-12-05 01:44:05","endLine":122,"groupId":"102874","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testAdds","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/36/298b57878f7934393de2a7bf1fa972bf50eab9.src","preCode":"  public void testAdds() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 500;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n\n    Assert.assertEquals(\"There have been no updates yet, so there shouldn't have been any commits\", 0,\n        hardCommitTracker.getCommitCount());\n\n    long tlogSizePreUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertEquals(\"There have been no updates yet, so tlog should be empty\", 0, tlogSizePreUpdates);\n\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\", hardCommitTracker.getCommitCount() > 0);\n    long tlogSizePostUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostUpdates < maxFileSizeBound);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"},{"authorDate":"2018-12-05 01:44:05","commitOrder":3,"curCode":"  public void testRedundantDeletes() throws Exception {\n\n    Assert.assertEquals(\"There have been no updates yet, so there shouldn't have been any commits\", 0,\n                        hardCommitTracker.getCommitCount());\n\n    long tlogSizePreUpdates = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertEquals(\"There have been no updates yet, so tlog should be empty\", 0, tlogSizePreUpdates);\n    \n    \r\n    int numDocsToAdd = 150;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n\n    monitor.doStuffAndExpectAtLeastOneCommit(hardCommitTracker, updateHandler, () -> {\n        updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n      });\n    \n\n    \r\n    int numDeletesToSend = 500;\n    int docIdToDelete = 100;\n\n    SolrQueryRequestBase batchSingleDeleteRequest = new SolrQueryRequestBase(core, new MapSolrParams(new HashMap<>())) {};\n    List<String> docs = new ArrayList<>();\n    for (int i = 0; i < numDeletesToSend; i++) {\n      docs.add(delI(Integer.toString(docIdToDelete)));\n    }\n    batchSingleDeleteRequest.setContentStreams(toContentStreams(docs));\n    \n    monitor.doStuffAndExpectAtLeastOneCommit(hardCommitTracker, updateHandler, () -> {\n        updateRequestHandler.handleRequest(batchSingleDeleteRequest, updateResp);\n      });\n    \n  }\n","date":"2018-12-05 01:44:05","endLine":157,"groupId":"102874","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRedundantDeletes","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-solr-10-0.7/blobInfo/CC_OUT/blobs/36/298b57878f7934393de2a7bf1fa972bf50eab9.src","preCode":"  public void testRedundantDeletes() throws Exception {\n    int maxFileSizeBound = 1000;\n    \r\n    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);\n\n    \r\n    int numDocsToAdd = 150;\n    SolrQueryResponse updateResp = new SolrQueryResponse();\n    updateRequestHandler.handleRequest(constructBatchAddDocRequest(0, numDocsToAdd), updateResp);\n    waitForCommit(1000);\n\n    \r\n    int commitCountPreDeletes = hardCommitTracker.getCommitCount();\n\n    \r\n    int numDeletesToSend = 500;\n    int docIdToDelete = 100;\n\n    SolrQueryRequestBase batchSingleDeleteRequest = new SolrQueryRequestBase(core, new MapSolrParams(new HashMap<>())) {};\n    List<String> docs = new ArrayList<>();\n    for (int i = 0; i < numDeletesToSend; i++) {\n      docs.add(delI(Integer.toString(docIdToDelete)));\n    }\n    batchSingleDeleteRequest.setContentStreams(toContentStreams(docs));\n\n    updateRequestHandler.handleRequest(batchSingleDeleteRequest, updateResp);\n\n    \r\n    waitForCommit(1000);\n\n    \r\n    Assert.assertTrue(\"At least one commit should have occurred\",\n        hardCommitTracker.getCommitCount() > commitCountPreDeletes);\n    long tlogSizePostDeletes = updateHandler.getUpdateLog().getCurrentLogSizeFromStream();\n    Assert.assertTrue(\"Current tlog size is larger than the max bound\", tlogSizePostDeletes < maxFileSizeBound);\n  }\n","realPath":"solr/core/src/test/org/apache/solr/update/MaxSizeAutoCommitTest.java","repoName":"solr","snippetEndLine":0,"snippetStartLine":0,"startLine":125,"status":"M"}],"commitId":"868e005760e95b0e3632f9bc8cec57656aeddabc","commitMessage":"@@@SOLR-13032: harden MaxSizeAutoCommitTest to eliminate race conditions and eliminate use of arbitrary sleep\n","date":"2018-12-05 01:44:05","modifiedFileCount":"2","status":"M","submitter":"Chris Hostetter"}]
