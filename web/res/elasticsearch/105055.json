[{"authorTime":"2018-04-26 03:22:53","codes":[{"authorDate":"2018-04-26 03:22:53","commitOrder":1,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(3, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n                }\n        );\n    }\n","date":"2018-04-26 03:22:53","endLine":127,"groupId":"65636","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9b/5bc7541f2c2f69ee4ac3e2549a0dd7414901d8.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(3, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n                }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"B"},{"authorDate":"2018-04-26 03:22:53","commitOrder":1,"curCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n                Arrays.asList(\n                        \"2017-02-01T09:02:00.000Z\",\n                        \"2017-02-01T09:35:00.000Z\",\n                        \"2017-02-01T10:15:00.000Z\",\n                        \"2017-02-01T13:06:00.000Z\",\n                        \"2017-02-01T14:04:00.000Z\",\n                        \"2017-02-01T14:05:00.000Z\",\n                        \"2017-02-01T15:59:00.000Z\",\n                        \"2017-02-01T16:06:00.000Z\",\n                        \"2017-02-01T16:48:00.000Z\",\n                        \"2017-02-01T16:59:00.000Z\"\n                ),\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(6, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(3);\n                    assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(4);\n                    assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(5);\n                    assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n                }\n        );\n    }\n","date":"2018-04-26 03:22:53","endLine":231,"groupId":"65636","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/9b/5bc7541f2c2f69ee4ac3e2549a0dd7414901d8.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n                Arrays.asList(\n                        \"2017-02-01T09:02:00.000Z\",\n                        \"2017-02-01T09:35:00.000Z\",\n                        \"2017-02-01T10:15:00.000Z\",\n                        \"2017-02-01T13:06:00.000Z\",\n                        \"2017-02-01T14:04:00.000Z\",\n                        \"2017-02-01T14:05:00.000Z\",\n                        \"2017-02-01T15:59:00.000Z\",\n                        \"2017-02-01T16:06:00.000Z\",\n                        \"2017-02-01T16:48:00.000Z\",\n                        \"2017-02-01T16:59:00.000Z\"\n                ),\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(6, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(3);\n                    assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(4);\n                    assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(5);\n                    assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n                }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":187,"status":"B"}],"commitId":"d74fb9eb4559077e2d20b19a9ed62d9ff825027a","commitMessage":"@@@Opened x-pack ILM code\n","date":"2018-04-26 03:22:53","modifiedFileCount":"0","status":"B","submitter":"Tal Levy"},{"authorTime":"2019-05-07 05:17:11","codes":[{"authorDate":"2019-05-07 05:17:11","commitOrder":2,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }\n        );\n    }\n","date":"2019-05-07 05:17:11","endLine":260,"groupId":"65636","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/f6/71b21eb5e9b0c49e60b194b419f18b022ac45b.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(3, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n                }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"},{"authorDate":"2019-05-07 05:17:11","commitOrder":2,"curCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }\n        );\n    }\n","date":"2019-05-07 05:17:11","endLine":546,"groupId":"65636","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/f6/71b21eb5e9b0c49e60b194b419f18b022ac45b.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n                Arrays.asList(\n                        \"2017-02-01T09:02:00.000Z\",\n                        \"2017-02-01T09:35:00.000Z\",\n                        \"2017-02-01T10:15:00.000Z\",\n                        \"2017-02-01T13:06:00.000Z\",\n                        \"2017-02-01T14:04:00.000Z\",\n                        \"2017-02-01T14:05:00.000Z\",\n                        \"2017-02-01T15:59:00.000Z\",\n                        \"2017-02-01T16:06:00.000Z\",\n                        \"2017-02-01T16:48:00.000Z\",\n                        \"2017-02-01T16:59:00.000Z\"\n                ),\n                aggregation -> aggregation.dateHistogramInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n                histogram -> {\n                    List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                    assertEquals(6, buckets.size());\n\n                    Histogram.Bucket bucket = buckets.get(0);\n                    assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(1);\n                    assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(2);\n                    assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(3);\n                    assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(2, bucket.getDocCount());\n\n                    bucket = buckets.get(4);\n                    assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(1, bucket.getDocCount());\n\n                    bucket = buckets.get(5);\n                    assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                    assertEquals(3, bucket.getDocCount());\n                }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":459,"status":"M"}],"commitId":"290c8b8256fc4da512e7bbe1c727005c21d55a67","commitMessage":"@@@Force selection of calendar or fixed intervals in date histo agg (#33727)\n\nThe date_histogram accepts an interval which can be either a calendar \ninterval (DST-aware.  leap seconds.  arbitrary length of months.  etc) or \nfixed interval (strict multiples of SI units). Unfortunately this is inferred\nby first trying to parse as a calendar interval.  then falling back to fixed\nif that fails.\n\nThis leads to confusing arrangement where `1d` == calendar.  but \n`2d` == fixed.  And if you want a day of fixed time.  you have to \nspecify `24h` (e.g. the next smallest unit).  This arrangement is very\nerror-prone for users.\n\nThis PR adds `calendar_interval` and `fixed_interval` parameters to any\ncode that uses intervals (date_histogram.  rollup.  composite.  datafeed.  etc).\nCalendar only accepts calendar intervals.  fixed accepts any combination of\nunits (meaning `1d` can be used to specify `24h` in fixed time).  and both\nare mutually exclusive.  \n\nThe old interval behavior is deprecated and will throw a deprecation warning.\nIt is also mutually exclusive with the two new parameters. In the future the \nold dual-purpose interval will be removed.\n\nThe change applies to both REST and java clients.\n\n","date":"2019-05-07 05:17:11","modifiedFileCount":"51","status":"M","submitter":"Zachary Tong"},{"authorTime":"2019-08-27 02:21:42","codes":[{"authorDate":"2019-08-27 02:21:42","commitOrder":3,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2019-08-27 02:21:42","endLine":260,"groupId":"65636","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/4e/ba98dd49b9d8dea544775cf1e520575222b1ff.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"},{"authorDate":"2019-08-27 02:21:42","commitOrder":3,"curCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2019-08-27 02:21:42","endLine":546,"groupId":"65636","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/4e/ba98dd49b9d8dea544775cf1e520575222b1ff.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":459,"status":"M"}],"commitId":"1a0dddf4ad24b3f2c751a1fe0e024fdbf8754f94","commitMessage":"@@@Range Field support for Histogram and Date Histogram aggregations(#45395)\n\n * Add support for a Range field ValuesSource.  including decode logic for range doc values and exposing RangeType as a first class enum\n * Provide hooks in ValuesSourceConfig for aggregations to control ValuesSource class selection on missing & script values\n * Branch aggregator creation in Histogram and DateHistogram based on ValuesSource class.  to enable specialization based on type.  This is similar to how Terms aggregator works.\n * Prioritize field type when available for selecting the ValuesSource class type to use for an aggregation\n\n","date":"2019-08-27 02:21:42","modifiedFileCount":"44","status":"M","submitter":"Mark Tozzi"},{"authorTime":"2020-05-07 19:22:32","codes":[{"authorDate":"2020-05-07 19:22:32","commitOrder":4,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":270,"groupId":"65636","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(INSTANT_FIELD, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(DATE_FIELD),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":250,"status":"M"},{"authorDate":"2020-05-07 19:22:32","commitOrder":4,"curCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":556,"groupId":"65636","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(DATE_FIELD).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":469,"status":"M"}],"commitId":"0097a86d5389d990387005d64a908777dcf61ff6","commitMessage":"@@@Optimize date_histograms across daylight savings time (#55559)\n\nRounding dates on a shard that contains a daylight savings time transition\nis currently something like 1400% slower than when a shard contains dates\nonly on one side of the DST transition. And it makes a ton of short lived\ngarbage. This replaces that implementation with one that benchmarks to\nhaving around 30% overhead instead of the 1400%. And it doesn't generate\nany garbage per search hit.\n\nSome background:\nThere are two ways to round in ES:\n* Round to the nearest time unit (Day/Hour/Week/Month/etc)\n* Round to the nearest time *interval* (3 days/2 weeks/etc)\n\nI'm only optimizing the first one in this change and plan to do the second\nin a follow up. It turns out that rounding to the nearest unit really *is*\ntwo problems: when the unit rounds to midnight (day/week/month/year) and\nwhen it doesn't (hour/minute/second). Rounding to midnight is consistently\nabout 25% faster and rounding to individual hour or minutes.\n\nThis optimization relies on being able to *usually* figure out what the\nminimum and maximum dates are on the shard. This is similar to an existing\noptimization where we rewrite time zones that aren't fixed\n(think America/New_York and its daylight savings time transitions) into\nfixed time zones so long as there isn't a daylight savings time transition\non the shard (UTC-5 or UTC-4 for America/New_York). Once I implement\ntime interval rounding the time zone rewriting optimization *should* no\nlonger be needed.\n\nThis optimization doesn't come into play for `composite` or\n`auto_date_histogram` aggs because neither have been migrated to the new\n`DATE` `ValuesSourceType` which is where that range lookup happens. When\nthey are they will be able to pick up the optimization without much work.\nI expect this to be substantial for `auto_date_histogram` but less so for\n`composite` because it deals with fewer values.\n\nNote: My 30% overhead figure comes from small numbers of daylight savings\ntime transitions. That overhead gets higher when there are more\ntransitions in logarithmic fashion. When there are two thousand years\nworth of transitions my algorithm ends up being 250% slower than rounding\nwithout a time zone.  but java time is 47000% slower at that point. \nallocating memory as fast as it possibly can.\n","date":"2020-05-07 19:22:32","modifiedFileCount":"19","status":"M","submitter":"Nik Everett"},{"authorTime":"2020-05-07 19:22:32","codes":[{"authorDate":"2020-05-20 01:48:25","commitOrder":5,"curCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-20 01:48:25","endLine":353,"groupId":"65636","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/3d/ba9219ab182e44d9bfe6c1f1f0e90a511b07c5.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), dataset,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":333,"status":"M"},{"authorDate":"2020-05-07 19:22:32","commitOrder":5,"curCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-05-07 19:22:32","endLine":556,"groupId":"65636","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/98/a58adfed6f2db5530932118b338a533b80315d.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":469,"status":"N"}],"commitId":"bea2341c9e12a2d28e7efa1b0cd35f6ebfedc0db","commitMessage":"@@@Save memory when date_histogram is not on top (#56921)\n\nWhen `date_histogram` is a sub-aggregator it used to allocate a bunch of\nobjects for every one of it's parent's buckets. This uses the data\nstructures that we built in #55873 rework the `date_histogram`\naggregator instead of all of the allocation.\n\nPart of #56487","date":"2020-05-20 01:48:25","modifiedFileCount":"7","status":"M","submitter":"Nik Everett"},{"authorTime":"2020-08-07 05:14:20","codes":[{"authorDate":"2020-08-07 05:14:20","commitOrder":6,"curCode":"    public void testIntervalYear() throws IOException {\n        testSearchCase(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-08-07 05:14:20","endLine":288,"groupId":"105055","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testIntervalYear","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/d2/97d9fabc6139339ee1186ab355b5d85c4dbf7f.src","preCode":"    public void testIntervalYear() throws IOException {\n        testBothCases(LongPoint.newRangeQuery(SEARCHABLE_DATE, asLong(\"2015-01-01\"), asLong(\"2017-12-31\")), DATASET,\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.YEAR).field(AGGREGABLE_DATE),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(3, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2015-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2016-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-01-01T00:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":268,"status":"M"},{"authorDate":"2020-08-07 05:14:20","commitOrder":6,"curCode":"    public void testIntervalHour() throws IOException {\n        testSearchCase(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testSearchCase(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","date":"2020-08-07 05:14:20","endLine":574,"groupId":"105055","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testIntervalHour","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-elasticsearch-10-0.7/blobInfo/CC_OUT/blobs/d2/97d9fabc6139339ee1186ab355b5d85c4dbf7f.src","preCode":"    public void testIntervalHour() throws IOException {\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.calendarInterval(DateHistogramInterval.HOUR).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n        testBothCases(new MatchAllDocsQuery(),\n            Arrays.asList(\n                \"2017-02-01T09:02:00.000Z\",\n                \"2017-02-01T09:35:00.000Z\",\n                \"2017-02-01T10:15:00.000Z\",\n                \"2017-02-01T13:06:00.000Z\",\n                \"2017-02-01T14:04:00.000Z\",\n                \"2017-02-01T14:05:00.000Z\",\n                \"2017-02-01T15:59:00.000Z\",\n                \"2017-02-01T16:06:00.000Z\",\n                \"2017-02-01T16:48:00.000Z\",\n                \"2017-02-01T16:59:00.000Z\"\n            ),\n            aggregation -> aggregation.fixedInterval(new DateHistogramInterval(\"60m\")).field(AGGREGABLE_DATE).minDocCount(1L),\n            histogram -> {\n                List<? extends Histogram.Bucket> buckets = histogram.getBuckets();\n                assertEquals(6, buckets.size());\n\n                Histogram.Bucket bucket = buckets.get(0);\n                assertEquals(\"2017-02-01T09:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(1);\n                assertEquals(\"2017-02-01T10:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(2);\n                assertEquals(\"2017-02-01T13:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(3);\n                assertEquals(\"2017-02-01T14:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(2, bucket.getDocCount());\n\n                bucket = buckets.get(4);\n                assertEquals(\"2017-02-01T15:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(1, bucket.getDocCount());\n\n                bucket = buckets.get(5);\n                assertEquals(\"2017-02-01T16:00:00.000Z\", bucket.getKeyAsString());\n                assertEquals(3, bucket.getDocCount());\n            }, false\n        );\n    }\n","realPath":"server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java","repoName":"elasticsearch","snippetEndLine":0,"snippetStartLine":0,"startLine":487,"status":"M"}],"commitId":"5e3ea6eb11c68bdcc9adda51715a6e1fea9186d6","commitMessage":"@@@Merge branch 'master' into feature/runtime_fields\n","date":"2020-08-07 05:14:20","modifiedFileCount":"73","status":"M","submitter":"Nik Everett"}]
