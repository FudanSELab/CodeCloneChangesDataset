[{"authorTime":"2020-02-06 05:09:04","codes":[{"authorDate":"2020-02-06 05:09:04","commitOrder":1,"curCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","date":"2020-02-06 05:09:04","endLine":79,"groupId":"2873","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testNormalUsage","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/73/2ae8faab5a235602bf1429f8b4c47a9804b548.src","preCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"B"},{"authorDate":"2020-02-06 05:09:04","commitOrder":1,"curCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","date":"2020-02-06 05:09:04","endLine":92,"groupId":"2873","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testDuplicateAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/73/2ae8faab5a235602bf1429f8b4c47a9804b548.src","preCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"B"}],"commitId":"bee3ed273424b9614082be8c76eb80428a97ff3a","commitMessage":"@@@Merge Waged rebalancer branch code to master. (#724)\n\n* Define the WAGED rebalancer interfaces.\n\nThis is the intial check in for the future development of the WAGED rebalancer.\nAll the components are placeholders. They will be implemented gradually.\n\n* Adding the configuration items of the WAGED rebalancer. (#348)\n\n* Adding the configuration items of the WAGED rebalancer.\n\nIncluding: Instance Capacity Keys.  Rebalance Preferences.  Instance Capacity Details.  Partition Capacity (the weight) Details.\nAlso adding test to cover the new configuration items.\n\n* Implement the WAGED rebalancer cluster model (#362)\n\n* Introduce the cluster model classes to support the WAGED rebalancer.\n\nImplement the cluster model classes with the minimum necessary information to support rebalance.\nAdditional field/logics might be added later once the detailed rebalance logic is implemented.\n\nAlso add related tests.\n\n* Change the rebalancer assignment record to be ResourceAssignment instead of IdealState. (#398)\n\nResourceAssignment fit the usage better. And there will be no unnecessary information to be recorded or read during the rebalance calculation.\n\n* Convert all the internal assignment state objects to be ResourceAssignment. (#399)\n\nThis is to avoid unnecessary information being recorded or read.\n\n* Implement Cluster Model Provider. (#392)\n\n* Implement Cluster Model Provider.\n\nThe model provider is called in the WAGED rebalancer to generate CLuster Model based on the current cluster status.\nThe major responsibility of the provider is to parse all the assignable replicas and identify which replicas need to be reassigned. Note that if the current best possible assignment is still valid.  the rebalancer won't need to calculate for the partition assignment.\n\nAlso.  add unit tests to verify the main logic.\n\n* Add ChangeDetector interface and ResourceChangeDetector implementation (#388)\n\nAdd ChangeDetector interface and ResourceChangeDetector implementation\n\nIn order to efficiently react to changes happening to the cluster in the new WAGED rebalancer.  a new component called ChangeDetector was added.\n\nChangelist:\n1. Add ChangeDetector interface\n2. Implement ResourceChangeDetector\n3. Add ResourceChangeCache.  a wrapper for critical cluster metadata\n4. Add an integration test.  TestResourceChangeDetector\n\n* Add cluster level default instance config. (#413)\n\nThis config will be applied to the instance when there is no (or empty) capacity configuration in the Instance Config.\nAlso add unit tests.\n\n* Redefine the hard/soft constraints (#422)\n\n* Refactor the interfaces of hard/soft constraints and a central place to keep the softConstraint weights\n\n* Refine the WAGED rebalancer related interfaces for integration (#431)\n\n* Refine the WAGED rebalancer related interfaces and initial integrate with the BestPossibleStateCalStage.\n\n- Modify the BestPossibleStateCalStage logic to plugin the WAGED rebalancer.\n- Refine ClusterModel to integrate with the ClusterDataDetector implementation.\n- Enabling getting the changed details for Cluster Config in the change detector. Which is required by the WAGED rebalancer.\n\n* Resubmit the change: Refine the WAGED rebalancer related interfaces for integration (#431)\n\n* Refine the WAGED rebalancer related interfaces and initial integrate with the BestPossibleStateCalStage.\n\n- Modify the BestPossibleStateCalStage logic to plugin the WAGED rebalancer.\n- Refine ClusterModel to integrate with the ClusterDataDetector implementation.\n- Enabling getting the changed details for Cluster Config in the change detector. Which is required by the WAGED rebalancer.\n\n* Bring back the interface class and algorithm placeholder class that was removed prematurely.\n\n* Revert \"Refine the WAGED rebalancer related interfaces for integration (#431)\" (#437)\n\nThis reverts commit 08a2015c617ddd3c93525afc572081a7836f9476.\n\n* Modify the expected change type from CONFIG to CLUSTER_CONFIG in the WAGED rebalancer. (#438)\n\nCONFIG is for generic configuration items. That will be too generic for the rebalancer.\nModify to check for CLUSTER_CONFIG to avoid confusion.\n\n* Add special treatment for ClusterConfig\n\nThis diff allows callers of getChangeType to iterate over the result of getChangeType() by changing determinePropertyMapByType so that it just returns an empty map for ClusterConfig.\n\n* Record the replica objects in the AssignableNode in addition to the partition name (#440)\n\nThe replica instances are required while the rebalance algorithm generating ResourceAssignment based on the AssignableNode instances.\nRefine the methods of the AssignableNode for better code style and readability.\nAlso.  modify the related test cases to verify state information and new methods.\n\n* Add BucketDataAccessor for large writes\n\nFor the new WAGED rebalancer.  it's necessary to have a data accessor that will allow writes of data exceeding 1MB. ZooKeeper's ZNode size is capped at 1MB.  so BucketDataAccessor interface and ZkBucketDataAccessor help us achieve this.\nChangelist:\n1. Add BucketDataAccessor and ZkBucketDataAccessor\n2. Add necessary serializers\n3. Add an integration test against ZK\n\n* Implement the basic constraint based algorithm (#381)\n\nImplement basic constraint algorithm: Greedy based.  each time it picks the best scores given each replica and assigns the replica to the node. It doesn't guarantee to achieve global optimal but local optimal result\n\nThe algorithm is based on a given set of constraints\n\n* HardConstraint: Approve or deny the assignment given its condition.  any assignment cannot bypass any \"hard constraint\"\n* SoftConstraint: Evaluate the assignment by points/rewards/scores.  a higher point means a better assignment\nThe goal is to avoid all \"hard constraints\" while accumulating the most points(rewards) from \"soft constraints\"\n\n* Validate the instance capacity/partition weight configuration while constructing the assignable instances (#451)\n\nCompare the configure items with the required capacity keys that are defined in the cluster config when build the assignable instances.\n- According to the design.  all the required capacity keys must appear in the instance capacity config.\n- As for the partition weights.  the corresponding weight item will be filled with value 0 if the required capacity key is not specified in the resource config.\n\n* Implement the WAGED rebalancer with the limited functionality. (#443)\n\nThe implemented rebalancer supports basic rebalance logic. It does not contain the logic to support delayed rebalance and user-defined preference list.\n\nAdded unit test to cover the main workflow of the WAGED rebalancer.\n\n* HardConstraints Implementation and unit tests (#433)\n\n* Implement all of basic Hard Constraints\n1. Partitions count cannot exceed instance's upper limit\n2. Fault zone aware (no same partitions on the same zone)\n3. Partitions weight cannot exceed instance's capacity\n4. Cannot assign inactived partitions\n5. Same partition of different states cannot co-exist in one instance\n6. Instance doesn't have the tag of the replica\n\n* Implement AssignmentMetadataStore (#453)\n\nImplement AssignmentMetadataStore\n\nAssignmentMetadataStore is a component for the new WAGED Rebalaner. It provides APIs that allows the rebalancer to read and write the baseline and best possible assignments using BucketDataAccessor.\n\nChangelist:\n1. Add AssignmentMetadataStore\n2. Add an integration test: TestAssignmentMetadataStore\n\n* Fix TestWagedRebalancer and add constructor in AssignmentMetadataStore\n\nTestWagedRebalancer was failing because it was not using a proper HelixManager to instantiate a mock version of AssignmentMetadataStore. This diff refactors the constructors in AssignmentMetadataStore and fixes the failing test.\n\n* Implement one of the soft constraints (#450)\n\nImplement Instance Partitions Count soft constraint.\nEvaluate by instance's current partition count versus estimated max partition count.\nIntuitively.  Encourage the assignment if the instance's occupancy rate is below average;\nDiscourage the assignment if the instance's occupancy rate is above average.\n\nThe final normalized score will be within [0.  1].\nThe implementation of the class will depend on the cluster current total partitions count as the max score.\n\n* Add soft constraint: ResourcetopStateAntiAffinityConstraint (#465)\n\nAdd ResourcetopStateAntiAffinityConstraint\n\nThe more total top state partitions assigned to the instance.  the lower the score.  vice versa.\n\n* Implement MaxCapacityUsageInstanceConstraint soft constraint (#463)\n\nThe constraint evaluates the score by checking the max used capacity key out of all the capacity\nkeys.\nThe higher the maximum usage value for the capacity key.  the lower the score will be.  implying\nthat it is that much less desirable to assign anything on the given node.\nIt is a greedy approach since it evaluates only the most used capacity key.\n\n* Add soft constraint: ResourcePartitionAntiAffinityConstraint (#464)\n\nIf the resource of the partition overall has a light load on the instance.  the score is higher compared to case when the resource is heavily loaded on the instance\n\n* Improve ResourceTopStateAntiAffinityConstraint (#475)\n\n- fix the min max range to be [0. 1]\n- add unit test for normalized score\n\n* Adjust the expected replica count according to fault zone count. (#476)\n\nThe rebalancer should determine the expected replica count according to the fault zone instead of the node count only.\n\n* PartitionMovementSoftConstraint Implementation (#474)\n\nAdd soft constraint: partition movement constraint\n\nEvaluate the proposed assignment according to the potential partition movements cost.\nThe cost is evaluated based on the difference between the old assignment and the new assignment.\n\n* Add the remaining implementation of ConstraintBasedAlgorithmFactory (#478)\n\nImplementation of ConstraintBasedAlgorithmFactory and the soft constraint weight model.\nRemove SoftConstraintWeightModel class.\nGet the rebalance preference and adjust the corresponding weight.\nPass the preference keys instead of cluster config.\n\n* Integrate the WAGED rebalancer with all the related components. (#466)\n\n1. Integrate with the algorithm.  assignment metadata store.  etc. Fix several conflicting interfaces and logics so as to all the rebalancer run correctly.\n2. Complete OptimalAssignment.\n3. Add integration tests to ensure the correctness of rebalancing logic.\n\n* Separate AssignableNode properties by Immutable and Mutable (#485)\n\nMake AssignableNode properties different by Immutable and Mutable\n- It helps detect any wrong usage of these properties early\n\n* Enable maintenance mode for the WAGED rebalancer.\n\nThe maintenance mode rebalance logic keeps the same as the previous feature.\nAdd more tests about partition migration and node swap that requires maintenance mode.\n\n* Add delayed rebalance and user-defined preference list features to the WAGED rebalancer. (#456)\n\n- Add delayed rebalance and user-defined preference list features to the WAGED rebalancer.\n- Refine the delayed rebalance usage in the waged rebalancer.\n- Add the delayed rebalance scheduling logic.\n- Add the necessary tests. And fix TestMixedModeAutoRebalance and all delayed rebalance tests.\n\n* Adjust the topology processing logic for instance to ensure backward compatibility.\n\n* Load soft constraint weight from resources/properties file (#492)\n\nLoad the soft constraint's weight from a properties file.\nIt makes easier for us to adjust weights in the future.\n\n* Add latency metric components for WAGED rebalancer (#490)\n\nAdd WAGED rebalancer metric framework and latency metric implementation\n\nChangelist:\n1. Add WAGED rebalancer metric interface\n2. Implement latency-related metrics\n3. Integrate latency metrics into WAGED rebalancer\n4. Add tests\n\n* Fixing rebalance cache issue and stablize the tests. (#510)\n\n1. Fix the DelayedAutoRebalancer Cache issue that ClusterConfig change won't trigger rebalance. The current workaround in our code blocks the WAGED rebalancer logic. So we need to fix it while merging the WAGED rebalancer code.\n2. Refine the ResourceChangeDetector's usage in the WAGED rebalancer so as to avoid unnecessary global rebalance.\n3. Extend the StrictMatchExternalViewVerifier so it can be used to test the WAGED rebalance feature.\n\n* More strict partition weight validation while creating the cluster model. (#511)\n\n1. If any capacity key is not configured in the Resource Config (or default weight) as the partition weight.  the config is invalid.\n2. If any partition weight is configured with a negative number.  the config is invalid.\nNote that the rebalancer will not compute a new assignment if any capacity/weight config is invalid.\n\n* Increase parallelism for ZkBucketDataAccessor (#506)\n\n* Increase parallelism for ZkBucketDataAccessor\n\nThis diff improves parallelism and throughput for ZkBucketDataAccessor. It implements the following ideas:\n1. Optimistic Concurrency Control\n2. Monotonically Increasing Version Number\n3. Garbage Collection of Stale Metadata\n4. Retrying Reads Upon Failure\n\n* The WAGED rebalancer returns the previously calculated assignment on calculation failure (#514)\n\n* The WAGED rebalancer returns the previously calculated assignment on calculation failure.\n\nThis is to protect the cluster assignment on a rebalancing algorithm failure. For example.  the cluster is out of capacity. In this case.  the rebalancer will keep using the previously calculated mapping.\nAlso.  refine the new metric interface.  and add the RebalanceFailureCount metric for recording the failures.\n\nModify the test cases so that DBs from different test cases have a different name. This is to avoid previous test records to be returned by the rebalancer on calculation error.\n\n* Make log clearer after finishing calculateAssignment. (#531)\n\nMake log clearer after finishing calculateAssignment.\n\n* Implement monitoring mbeans for the WAGED rebalancer. (#525)\n\nChange list:\n1. GlobalBaselineCalcCounter: Counter of the global rebalance.\n2. PartialRebalanceCounter: Counter of the partial rebalance done.\n3. BaselineDivergenceGauge: Gauge of the difference at replica level between the Baseline and the Best Possible assignments.\n\n* Refine the rebalance scope calculating logic in the WAGED rebalancer. (#519)\n\n* Refine the rebalane scope calculating logic in the WAGED rebalancer.\n\n1. Ignore the IdealState mapping/listing fields if the resource is in FULL_AUTO mode.\n2. On IdealState change.  the resource shall be fully rebalanced since some filter conditions might be changed. Such as instance tag.\n3. Live instance change (node newly connected) shall trigger full rebalance so partitions will be re-assigned to the new node.\n4. Modify the related test cases.\n5. Adding an option to the change detector so if it is used elsewhere.  the caller has an option to listen to any change.\n\n* Make WagedRebalancer static by creating a ThreadLocal (#540)\n\nZKBucketDataAccessor has a GC logic.  but this is only valid if the ZkClient inside it is active and not closed. Currently.  WAGED rebalancer generates an instance of AssignmentMetadataStore every time it rebalances.  which does not allow the internal ZkBucketDataAccessor to garbage collect the assignment metadata it wrote previously.\n\nThis diff makes the entire WagedRebalancer object a ThreadLocal.  which has the effect of making it essentially static across different runs of the pipeline.\n\n* Change change detector to a regular field in the WAGED rebalancer instead of static threadlocal. (#543)\n\n* Change change detector to regular field instead of static thread-local.\n\nThe rebalance has been modified to be a thread-local object. So there is no need to keep the change detector as thread-local.\nThis may cause potential problems.\nIn addition.  in order to avoid resource leakage.  implement the finalize method of the WagedRebalancer to close all connections.\n\n* Refactor soft constraints to simply the algorithm and fix potential issues. (#520)\n\n* Refactor soft constraints to simply the algorithm and fix potential issues.\n\n1. Check for zero weight so as to avoid unnecessary calculations.\n2. Simply the soft constraint interfaces and implementations. Avoid duplicate code.\n3. Adjust partition movements constraint logic to reduce the chance of moving partition when the baseline and best possible assignment diverge.\n4. Estimate utilization in addition to the other usage estimation. The estimation will be used as a base when calculating the capacity usage score. This is to ensure the algorithm treats different clusters with different overall usage in the same way.\n5. Fix the issue that high utilization calculation does not consider the current proposed replica usage.\n6. Use Sigmoid to calculate usage-based soft constraints score. This enhances the assignment result of the algorithm.\n7. Adjust the related test cases.\n\n* Minor fix for the constraints related tests. (#545)\n\nMinor fix for the constraints related tests.\n\n* Adjust the replica rebalance calculating ordering to avoid static order. (#535)\n\n* Adjust the replica rebalance calculating ordering to avoid static order.\n\nThe problem of a static order is that the same set of replicas will always be the ones that are moved or state transited during the rebalance.\nThis randomize won't change the algorithm's performance. But it will help the Helix to eliminate very unstable partitions.\n\n* Implement increment() method in CountMetric class. (#537)\n\nAbstract method increaseCount() in CountMetric is a generic method used in inherited classes. We should implement this method in CountMetric to reduce duplicate code in inherited classes.\nChange list:\n1. Move increaseCount() to CountMetric.\n2. Change the name to increment() and implement the method.\n\n* Modify the ivy file to add the new math3 lib dependency. (#546)\n\nModify the ivy file to add the new math3 lib dependency.\n\n* Fix a missing parameter when the WAGED rebalancer init the change detector. (#547)\n\nThis parameter was missed during the previous change.\n\n* Add the new Rebalancer monitor domain to the active domain list. (#550)\n\nAdd the new Rebalancer monitor domain to the active domain list.\n\n* Refine ivy file config. The org were not configured correctly. (#551)\n\n* Use a deep copy of the new best possible assignment for measuring baseline divergence. (#542)\n\nThe new assignment is really critical in waged rebalancer. If there is any potential changes in measure baseline divergence.  waged rebalancer may not work correctly.\nTo avoid changes of the new assignment and make it safe when being used to measure baseline divergence.  use a deep copy of the new assignment.\n\n* Add max capacity usage metric for instance monitor. (#548)\n\nWe need to monitor instance's max utilization in purpose of understanding what the max capacity usage is and knowing the status of the instance.\n\nChange list:\n1. Change instance monitor to extend dynamic metric.  and change code logic in ClusterStatusMonitor to adapt the InstanceMonitor changes.\n2. Add APIs for get/update MaxCapacityUsage.\n3. Add an API in cluster status monitor to update max capacity usage.\n4. Add unit tests for instance monitor and updateing max capacity usage.\n\n* Fix formula incorrection in the comment for measuring baseline divergence. (#559)\n\nFix incorrect formula in the comment for measuring baseline divergence.\n\n* Avoid redundant writes in AssignmentMetadataStore (#564)\n\nFor the WAGED rebalancer.  we persist the cluster's mapping via AssignmentMetadataStore every pipeline. However.  if there are no changes made to the new assignment from the old assignment.  this write is not necessary. This diff checks whether they are equal and skips the write if old and new assignments are the same.\n\n* Filter resource map with ideal states for instance capacity metrics. (#574)\n\nResourceToReblance map also has resources from current states. And this causes null pointer exceptions at parsing all replicas stage when the resource is not in ideal states. This diff fixes the issue by only using the resources in ideal states to parse all replicas.\n\n* Introduce Dry-run Waged Rebalancer for the verifiers and tests. (#573)\n\nUse a dry-run rebalancer to avoid updating the persisted rebalancer status in the verifiers or tests.\nAlso.  refine several rebalancer related interfaces so as to simplify the dry-run rebalancer implementation.\nConvert the test cases back to use the BestPossibleExternalViewVerifier.\n\nAdditional fixing:\n- Updating the rebalancer preference for every rebalancer.compute calls. Since the preference might be updated at runtime.\n- Fix one minor metric domain name bug in the WagedRebalancerMetricCollector.\n- Minor test case fix to make them more stable after the change.\n\n* Change ClusterConfig.setDefaultCapacityMap to be private. (#590)\n\nChange ClusterConfig.setDefaultCapacityMap to be private.\n\n* Add Java API for adding and validating resources for WAGED rebalancer (#570)\n\nAdd Java API methods for adding and validating resources for WAGED rebalancer. This is a set of convenience APIs provided through HelixAdmin the user could use to more easily add resources and validate them for WAGED rebalance usage.\nChangelist:\n1. Add API methods in HelixAdmin\n2. Implement the said methods\n3. Add tests\n\n* Change calculation for baseline divergence. (#598)\n\nChange the calculation for baseline divergence: 0.0 means no difference.  1.0 means all are different.\n\n* Improve the WAGED rebalancer performance. (#586)\n\nThis change improves the rebalance's speed by 2x to 5x depends on the host capacity.\n\nParallelism the loop processing whenever possible and help to improve the performance. This does not change the logic.\nAvoid some duplicate logic in the loop. Put the calculation outside the loop and only do it once.\n\n* Fix the unstable test TestZeroReplicaAvoidance. (#603)\n\nFix the unstable test TestZeroReplicaAvoidance by waiting.\nThis is a temporary resolution before we fix issue #526. Marked it in the TODO comment so easier for us to remove the wait in batch later.\n\n* Add REST API endpoints for WAGED Rebalancer (#611)\n\nWe want to make WAGED rebalancer (weight-aware) easier to use. One way to do this is to allow the user to easily add resources with weight configuration set by providing REST endpoints. This change adds the relevant REST endpoints based on the HelixAdmin APIs added in (#570).\n\nBasically.  this commit uses existing REST endpoints whose hierarchy is defined by REST resource. What this commit does to the existing endpoints is 1) Add extra commands 2) Add a WAGED command as a QueryParam so that WAGED logic could be included.\n\nThis change is backward-compatible because it keeps the original behavior when no commands are provided by using @DefaultValue annotation.\n\n* Fix a potential issue in the ResourceChangeSnapshot. (#635)\n\nThe trim logic in the ResourceChangeSnapshot for cleaning up the IdealState should not clear the whole map. This will cause the WAGED rebalancer ignores changes such as new partitions into the partition list.\nModify the test case accordingly.\n\n* Simply and enhance the RebalanceLatencyGauge so it can be used in multi-threads. (#636)\n\nThe previous design of RebalanceLatencyGauge won't support asynchronous metric data emitting. This PR adds support by using a ThreadLocal object.\nThe metric logic is not changed.\n\n* Add new WAGED rebalancer config item \"GLOBAL_REBALANCE_ASYNC_MODE\". (#637)\n\nThis option will be used by the WAGED rebalancer to determine if the global rebalance should be performed asynchronously.\n\n* Decouple the event type and the scheduled rebalance cache refresh option. (#638)\n\nThe previous design is that both on-demand and periodic rebalance scheduling task will request for a cache refresh. This won't be always true moving forward.\nFor example.  the WAGED rebalancer async baseline calculating requests for a scheduled rebalance. But cache refresh won't be necessary.\nThis PR does not change any business logic. It prepares for future feature change.\nThis PR ensures strict backward compatibility.\n\n* Improve the algorithm so it prioritizes the assignment to the idle nodes when the constraint evaluation results are the same (#651)\n\nThis is to get rid of the randomness when the algorithm result is a tie. Usually.  when the algorithm picks up the nodes with the same score.  more partition movements will be triggered on a cluster change.\n\n* Refine the WAGED rebalancer to minimize the partial rebalance workload. (#639)\n\n* Refine the WAGED rebalancer to minimize the partial rebalance workload.\n\nSplit the cluster module calculation method so that different rebalance logic can have different rebalance scope calculation logic.\nAlso.  refine the WAGED rebalancer logic to reduce duplicate code.\n\n* Refine methods name and comments. (#664)\n\n* Refine methods name and comments.\n\n* Asynchronously calculating the Baseline (#632)\n\n* Enable the Baseline calculation to be asynchronously done.\n\nThis will greatly fasten the rebalance speed. Basically.  the WAGED rebalancer will firstly partial rebalance to recover the invalid replica allocations (for example.  the ones that are on a disabled instance). Then it calculates the new baseline by global rebalancing.\n\n* Reorgnize the test case so the new WAGED expand cluster tests are not skipped. (#670)\n\nTestNG cannot handle test classes inheritance well. Some of the tests are skipped with the current design. Move the logic to the new test class so it is no longer a child of another test class. This ensures all the test cases are running.\n\n* Fix the Helix rest tests by cleaning up the environment before testing. (#679)\n\nThe validateWeight test methods in TestInstanceAccessor and TestPreInstanceAccessor are testing against the same instance config fields. There was a conflict if both of the test cases are executed in a certain order. This change adds cleanup logic so the shared fields will be empty before each test method starts.\n\n* Add instance capacity gauge (#557)\n\nWe need to monitor instance utilization in purpose of understanding what the instance capacity is.\n\nChange list:\n- Change instance monitor to update capacity\n- Change getAttribute to throw AttributeNotFoundException in DynamicMBeanProvider\n- Combine max usage and instance capacity update into one method in cluster status monitor\n- Add unit test\n\n* Add resource partition weight gauge (#686)\n\nWe would like to monitor the usage of each capacity for the resource partitions: gauge of the average partition weight for each CAPACITY key.\n\nChange list:\n- Add partition weight gauge metric to resource monitor.\n- Add two unit tests to cover new code.\n\n* Add WAGED rebalancer reset method to clean up cached status. (#696)\n\nThe reset method is for cleaning up any in-memory records within the WAGED rebalancer so we don't need to recreate one.\n\nDetailed change list:\n1. Add reset methods to all the stateful objects that are used in the WAGED rebalancer.\n2. Refine some of the potential race condition in the WAGED rebalancer components.\n3. Adjust the tests accordingly. Also adding new tests to cover the components reset / the WAGED rebalancer reset logic.\n\n* Reset the WAGED rebalancer once the controller newly acquires leadership. (#690)\n\nThis is to prevent any cached assignment information which is recorded during the previous session from impacting the rebalance result.\nDetailed change list:\n\nMove the stateful WAGED rebalancer to the GenericHelixController object instead of the rebalance stage. This is for resolving the possible race condition between the event processing thread and leader switch handling thread.\nAdding a new test regarding leadership switch to verify that the WAGED rebalancer has been reset after the processing.\n\nCo-authored-by: Hunter Lee <narendly@gmail.com>\nCo-authored-by: Yi Wang <ywang4@linkedin.com>\nCo-authored-by: Huizhi Lu <hulu@linkedin.com>\n","date":"2020-02-06 05:09:04","modifiedFileCount":"56","status":"B","submitter":"Jiajun Wang"},{"authorTime":"2019-08-03 12:21:49","codes":[{"authorDate":"2019-08-03 12:21:49","commitOrder":2,"curCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context = new ClusterContext(assignmentSet, 2);\n\n    \r\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 3);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","date":"2020-02-08 04:24:22","endLine":77,"groupId":"2873","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testNormalUsage","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/82/06f295b256bf2cca5441e0cf74049e6f44d732.src","preCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":41,"status":"M"},{"authorDate":"2019-08-03 12:21:49","commitOrder":2,"curCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context = new ClusterContext(assignmentSet, 2);\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","date":"2020-02-08 04:24:22","endLine":89,"groupId":"0","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testDuplicateAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/82/06f295b256bf2cca5441e0cf74049e6f44d732.src","preCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"M"}],"commitId":"253851a136bc248f0a0a2217c89af7e3293a3dbb","commitMessage":"@@@Implement the WAGED rebalancer cluster model (#362)\n\n* Introduce the cluster model classes to support the WAGED rebalancer.\n\nImplement the cluster model classes with the minimum necessary information to support rebalance.\nAdditional field/logics might be added later once the detailed rebalance logic is implemented.\n\nAlso add related tests.","date":"2020-02-08 04:24:22","modifiedFileCount":"6","status":"M","submitter":"jiajunwang"},{"authorTime":"2019-09-18 06:09:45","codes":[{"authorDate":"2019-09-18 06:09:45","commitOrder":3,"curCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context = new ClusterContext(assignmentSet, 2, new HashMap<>(), new HashMap<>());\n\n    \r\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 3);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","date":"2020-02-08 04:24:22","endLine":78,"groupId":"2873","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testNormalUsage","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/d8/b93c0e4e726dd7a27d15916b140790044dbdcf.src","preCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context = new ClusterContext(assignmentSet, 2);\n\n    \r\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 3);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2019-09-18 06:09:45","commitOrder":3,"curCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context = new ClusterContext(assignmentSet, 2, new HashMap<>(), new HashMap<>());\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","date":"2020-02-08 04:24:22","endLine":90,"groupId":"0","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testDuplicateAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/d8/b93c0e4e726dd7a27d15916b140790044dbdcf.src","preCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context = new ClusterContext(assignmentSet, 2);\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":81,"status":"M"}],"commitId":"d2ffd00f3e488ab3825c0ea1d2d712bb12aef09d","commitMessage":"@@@PartitionMovementSoftConstraint Implementation (#474)\n\nAdd soft constraint: partition movement constraint\n\nEvaluate the proposed assignment according to the potential partition movements cost.\nThe cost is evaluated based on the difference between the old assignment and the new assignment.","date":"2020-02-08 04:24:22","modifiedFileCount":"6","status":"M","submitter":"Yi Wang"},{"authorTime":"2019-10-26 12:56:46","codes":[{"authorDate":"2019-10-26 12:56:46","commitOrder":4,"curCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","date":"2020-02-08 04:24:22","endLine":79,"groupId":"2873","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testNormalUsage","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/73/2ae8faab5a235602bf1429f8b4c47a9804b548.src","preCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context = new ClusterContext(assignmentSet, 2, new HashMap<>(), new HashMap<>());\n\n    \r\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 3);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2019-10-26 12:56:46","commitOrder":4,"curCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","date":"2020-02-08 04:24:22","endLine":92,"groupId":"2873","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testDuplicateAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/73/2ae8faab5a235602bf1429f8b4c47a9804b548.src","preCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context = new ClusterContext(assignmentSet, 2, new HashMap<>(), new HashMap<>());\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"3f237dff5a4582f25e8c284286d87e49eca22d84","commitMessage":"@@@Refactor soft constraints to simply the algorithm and fix potential issues. (#520)\n\n* Refactor soft constraints to simply the algorithm and fix potential issues.\n\n1. Check for zero weight so as to avoid unnecessary calculations.\n2. Simply the soft constraint interfaces and implementations. Avoid duplicate code.\n3. Adjust partition movements constraint logic to reduce the chance of moving partition when the baseline and best possible assignment diverge.\n4. Estimate utilization in addition to the other usage estimation. The estimation will be used as a base when calculating the capacity usage score. This is to ensure the algorithm treats different clusters with different overall usage in the same way.\n5. Fix the issue that high utilization calculation does not consider the current proposed replica usage.\n6. Use Sigmoid to calculate usage-based soft constraints score. This enhances the assignment result of the algorithm.\n7. Adjust the related test cases.","date":"2020-02-08 04:24:22","modifiedFileCount":"24","status":"M","submitter":"Jiajun Wang"},{"authorTime":"2019-10-26 12:56:46","codes":[{"authorDate":"2021-03-02 05:40:04","commitOrder":5,"curCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n    \r\n    \r\n    Assert.assertEquals(context.getEstimatedMaxUtilization(), 16.0 / 20.0, 0.005);\n    Assert.assertEquals(context.getEstimatedTopStateMaxUtilization(), 8.0 / 20.0, 0.005);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","date":"2021-05-04 07:28:23","endLine":83,"groupId":"10302","id":9,"instanceNumber":1,"isCurCommit":1,"methodName":"testNormalUsage","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/71/71755e9746c17f570164659a1d83d6556d294d.src","preCode":"  public void testNormalUsage() throws IOException {\n    \r\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n\n    Assert.assertEquals(context.getEstimatedMaxPartitionCount(), 4);\n    Assert.assertEquals(context.getEstimatedMaxTopStateCount(), 2);\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), Collections.emptyMap());\n    for (String resourceName : _resourceNames) {\n      Assert.assertEquals(context.getEstimatedMaxPartitionByResource(resourceName), 2);\n      Assert.assertEquals(\n          context.getPartitionsForResourceAndFaultZone(_testFaultZoneId, resourceName),\n          Collections.emptySet());\n    }\n\n    \r\n    Map<String, Map<String, Set<String>>> expectedFaultZoneMap = Collections\n        .singletonMap(_testFaultZoneId, assignmentSet.stream().collect(Collectors\n            .groupingBy(AssignableReplica::getResourceName,\n                Collectors.mapping(AssignableReplica::getPartitionName, Collectors.toSet()))));\n\n    assignmentSet.stream().forEach(replica -> context\n        .addPartitionToFaultZone(_testFaultZoneId, replica.getResourceName(),\n            replica.getPartitionName()));\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n\n    \r\n    expectedFaultZoneMap.get(_testFaultZoneId).get(_resourceNames.get(0))\n        .remove(_partitionNames.get(0));\n    Assert.assertTrue(context.removePartitionFromFaultZone(_testFaultZoneId, _resourceNames.get(0),\n        _partitionNames.get(0)));\n\n    Assert.assertEquals(context.getAssignmentForFaultZoneMap(), expectedFaultZoneMap);\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":42,"status":"M"},{"authorDate":"2019-10-26 12:56:46","commitOrder":5,"curCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","date":"2020-02-08 04:24:22","endLine":92,"groupId":"10302","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testDuplicateAssign","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-helix-10-0.7/blobInfo/CC_OUT/blobs/73/2ae8faab5a235602bf1429f8b4c47a9804b548.src","preCode":"  public void testDuplicateAssign() throws IOException {\n    ResourceControllerDataProvider testCache = setupClusterDataCache();\n    Set<AssignableReplica> assignmentSet = generateReplicas(testCache);\n    ClusterContext context =\n        new ClusterContext(assignmentSet, generateNodes(testCache), new HashMap<>(),\n            new HashMap<>());\n    context.addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n    \r\n    context\n        .addPartitionToFaultZone(_testFaultZoneId, _resourceNames.get(0), _partitionNames.get(0));\n  }\n","realPath":"helix-core/src/test/java/org/apache/helix/controller/rebalancer/waged/model/TestClusterContext.java","repoName":"helix","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"N"}],"commitId":"c1eeec34c284828108279cb5f5843181a5584865","commitMessage":"@@@Add TopStateUsage constraint to Waged (#1652)\n\nAdd new top state weight-based constraint to Waged to ensure top state weight evenness.\n\nCo-authored-by: Neal Sun <nesun@nesun-mn1.linkedin.biz>","date":"2021-05-04 07:28:23","modifiedFileCount":"9","status":"M","submitter":"Neal Sun"}]
