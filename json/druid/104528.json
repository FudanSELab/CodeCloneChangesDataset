[{"authorTime":"2021-03-03 03:23:52","codes":[{"authorDate":"2021-03-03 03:23:52","commitOrder":1,"curCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE\n    );\n  }\n","date":"2021-03-03 03:23:52","endLine":1094,"groupId":"19074","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSegmentGranularityAndNullQueryGranularity","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b0/deee546550836611f13834cf7230e1115b793c.src","preCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1061,"status":"B"},{"authorDate":"2021-03-03 03:23:52","commitOrder":1,"curCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null)\n    );\n  }\n","date":"2021-03-03 03:23:52","endLine":1167,"groupId":"19074","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testQueryGranularityAndSegmentGranularityNonNull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/b0/deee546550836611f13834cf7230e1115b793c.src","preCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1131,"status":"B"}],"commitId":"b7b0ee83627dd7887392e8f9d6fb5cb29465c28c","commitMessage":"@@@Add query granularity to compaction task (#10900)\n\n* add query granularity to compaction task\n\n* fix checkstyle\n\n* fix checkstyle\n\n* fix test\n\n* fix test\n\n* add tests\n\n* fix test\n\n* fix test\n\n* cleanup\n\n* rename class\n\n* fix test\n\n* fix test\n\n* add test\n\n* fix test","date":"2021-03-03 03:23:52","modifiedFileCount":"15","status":"B","submitter":"Maytas Monsereenusorn"},{"authorTime":"2021-04-09 15:12:28","codes":[{"authorDate":"2021-04-09 15:12:28","commitOrder":2,"curCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","date":"2021-04-09 15:12:28","endLine":1343,"groupId":"19074","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSegmentGranularityAndNullQueryGranularity","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c4/faa5b2754ed36e4f3b71a6caa2cd64ceba3565.src","preCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1308,"status":"M"},{"authorDate":"2021-04-09 15:12:28","commitOrder":2,"curCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null),\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","date":"2021-04-09 15:12:28","endLine":1420,"groupId":"19074","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testQueryGranularityAndSegmentGranularityNonNull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/c4/faa5b2754ed36e4f3b71a6caa2cd64ceba3565.src","preCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null)\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1382,"status":"M"}],"commitId":"4576152e4a0213d17048a330e7089aa9d89f3972","commitMessage":"@@@Make dropExisting flag for Compaction configurable and add warning documentations (#11070)\n\n* Make dropExisting flag for Compaction configurable\n\n* fix checkstyle\n\n* fix checkstyle\n\n* fix test\n\n* add tests\n\n* fix spelling\n\n* fix docs\n\n* add IT\n\n* fix test\n\n* fix doc\n\n* fix doc","date":"2021-04-09 15:12:28","modifiedFileCount":"20","status":"M","submitter":"Maytas Monsereenusorn"},{"authorTime":"2021-07-21 02:44:19","codes":[{"authorDate":"2021-07-21 02:44:19","commitOrder":3,"curCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentCacheManagerFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","date":"2021-07-21 02:44:19","endLine":1343,"groupId":"104528","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSegmentGranularityAndNullQueryGranularity","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ac/9e3d011aef9e7655bf6426661366cead8b80e9.src","preCode":"  public void testSegmentGranularityAndNullQueryGranularity() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(new PeriodGranularity(Period.months(3), null, null), null),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        Granularities.NONE,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1308,"status":"M"},{"authorDate":"2021-07-21 02:44:19","commitOrder":3,"curCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentCacheManagerFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null),\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","date":"2021-07-21 02:44:19","endLine":1420,"groupId":"104528","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testQueryGranularityAndSegmentGranularityNonNull","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-druid-10-0.7/blobInfo/CC_OUT/blobs/ac/9e3d011aef9e7655bf6426661366cead8b80e9.src","preCode":"  public void testQueryGranularityAndSegmentGranularityNonNull() throws IOException, SegmentLoadingException\n  {\n    final List<ParallelIndexIngestionSpec> ingestionSpecs = CompactionTask.createIngestionSchema(\n        toolbox,\n        LockGranularity.TIME_CHUNK,\n        new SegmentProvider(DATA_SOURCE, new CompactionIntervalSpec(COMPACTION_INTERVAL, null)),\n        new PartitionConfigurationManager(TUNING_CONFIG),\n        null,\n        null,\n        new ClientCompactionTaskGranularitySpec(\n            new PeriodGranularity(Period.months(3), null, null),\n            new PeriodGranularity(Period.months(3), null, null)\n        ),\n        COORDINATOR_CLIENT,\n        segmentLoaderFactory,\n        RETRY_POLICY_FACTORY,\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n    final List<DimensionsSpec> expectedDimensionsSpec = ImmutableList.of(\n        new DimensionsSpec(getDimensionSchema(new DoubleDimensionSchema(\"string_to_double\")))\n    );\n\n    ingestionSpecs.sort(\n        (s1, s2) -> Comparators.intervalsByStartThenEnd().compare(\n            s1.getDataSchema().getGranularitySpec().inputIntervals().get(0),\n            s2.getDataSchema().getGranularitySpec().inputIntervals().get(0)\n        )\n    );\n    Assert.assertEquals(1, ingestionSpecs.size());\n    assertIngestionSchema(\n        ingestionSpecs,\n        expectedDimensionsSpec,\n        AGGREGATORS,\n        Collections.singletonList(COMPACTION_INTERVAL),\n        new PeriodGranularity(Period.months(3), null, null),\n        new PeriodGranularity(Period.months(3), null, null),\n        IOConfig.DEFAULT_DROP_EXISTING\n    );\n  }\n","realPath":"indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java","repoName":"druid","snippetEndLine":0,"snippetStartLine":0,"startLine":1382,"status":"M"}],"commitId":"94c1671eaf7b050972602fdedcb1971cdbde692d","commitMessage":"@@@Split SegmentLoader into SegmentLoader and SegmentCacheManager (#11466)\n\nThis PR splits current SegmentLoader into SegmentLoader and SegmentCacheManager.\n\nSegmentLoader - this class is responsible for building the segment object but does not expose any methods for downloading.  cache space management.  etc. Default implementation delegates the download operations to SegmentCacheManager and only contains the logic for building segments once downloaded. . This class will be used in SegmentManager to construct Segment objects.\n\nSegmentCacheManager - this class manages the segment cache on the local disk. It fetches the segment files to the local disk.  can clean up the cache.  and in the future.  support reserve and release on cache space. [See https://github.com/Make SegmentLoader extensible and customizable #11398]. This class will be used in ingestion tasks such as compaction.  re-indexing where segment files need to be downloaded locally.","date":"2021-07-21 02:44:19","modifiedFileCount":"41","status":"M","submitter":"Abhishek Agarwal"}]
