[{"authorTime":"2017-07-11 02:58:51","codes":[{"authorDate":"2017-01-13 03:46:02","commitOrder":3,"curCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() throws Exception {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","date":"2017-01-13 03:46:02","endLine":133,"groupId":"5602","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowStreamsExceptionWhenKeyDeserializationFails","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/a1/0e8f8fb6ca60fd78e1ee9ef14dcd617d71acd6.src","preCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() throws Exception {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":127,"status":"NB"},{"authorDate":"2017-07-11 02:58:51","commitOrder":3,"curCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() throws Exception {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","date":"2017-07-11 02:58:51","endLine":186,"groupId":"5602","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6c/45fd89edefe58cd23cfdee2ea39afa17e6a108.src","preCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() throws Exception {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"B"}],"commitId":"a1f97c8dc4edd49c7a8a2ebb72734728029a85aa","commitMessage":"@@@KAFKA-5157; Options for handling corrupt data during deserialization\n\nThis is the implementation of KIP-161: https://cwiki.apache.org/confluence/display/KAFKA/KIP-161%3A+streams+deserialization+exception+handlers\n\nAuthor: Eno Thereska <eno.thereska@gmail.com>\n\nReviewers: Damian Guy <damian.guy@gmail.com>.  Matthias J. Sax <matthias@confluent.io>\n\nCloses #3423 from enothereska/KAFKA-5157-deserialization-exceptions\n","date":"2017-07-11 02:58:51","modifiedFileCount":"12","status":"M","submitter":"Eno Thereska"},{"authorTime":"2017-07-11 02:58:51","codes":[{"authorDate":"2017-09-11 16:42:10","commitOrder":4,"curCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","date":"2017-09-11 16:42:10","endLine":156,"groupId":"5602","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowStreamsExceptionWhenKeyDeserializationFails","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/e9eac44a0122ce9bc7f072b5f72d0cfdb71669.src","preCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() throws Exception {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"M"},{"authorDate":"2017-07-11 02:58:51","commitOrder":4,"curCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() throws Exception {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","date":"2017-07-11 02:58:51","endLine":186,"groupId":"5602","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/6c/45fd89edefe58cd23cfdee2ea39afa17e6a108.src","preCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() throws Exception {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"N"}],"commitId":"c5464edbb7a6821e0a91a3712b1fe2fd92a22d68","commitMessage":"@@@KAFKA-5531; throw concrete exceptions in streams tests\n\n1. Now instead of just generic `Exception` methods declare more concrete\nexceptions throwing or don't declare any throwing at all.  if not needed.\n2. `SimpleBenchmark.run()` throws `RuntimeException`\n3. `SimpleBenchmark.produce()` throws `IllegalArgumentException`\n4. Expect `ProcessorStateException` in\n`StandbyTaskTest.testUpdateNonPersistentStore()`\n\n/cc enothereska\n\nAuthor: Evgeny Veretennikov <evg.veretennikov@gmail.com>\n\nReviewers: Damian Guy <damian.guy@gmail.com>\n\nCloses #3485 from evis/5531-throw-concrete-exceptions\n","date":"2017-09-11 16:42:10","modifiedFileCount":"106","status":"M","submitter":"Evgeny Veretennikov"},{"authorTime":"2018-04-18 04:13:15","codes":[{"authorDate":"2017-09-11 16:42:10","commitOrder":5,"curCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","date":"2017-09-11 16:42:10","endLine":156,"groupId":"5602","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowStreamsExceptionWhenKeyDeserializationFails","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c6/e9eac44a0122ce9bc7f072b5f72d0cfdb71669.src","preCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n                new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":150,"status":"N"},{"authorDate":"2018-04-18 04:13:15","commitOrder":5,"curCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","date":"2018-04-18 04:13:15","endLine":220,"groupId":"5602","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/be2926e93593165ccc1a058a8a694a14ae9e25.src","preCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() throws Exception {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":213,"status":"M"}],"commitId":"ac9c3ed0b43ee848e6e555a01c55ea2eee78540a","commitMessage":"@@@KAFKA-6376: preliminary cleanup (#4872)\n\nGeneral cleanup of Streams code.  mostly resolving compiler warnings and re-formatting.\n\nThe regular testing suite should be sufficient.\n\nReviewers: Matthias J. Sax <matthias@confluent.io>.  Guozhang Wang <wangguoz@gmail.com>","date":"2018-04-18 04:13:15","modifiedFileCount":"57","status":"M","submitter":"John Roesler"},{"authorTime":"2018-04-18 04:13:15","codes":[{"authorDate":"2020-02-13 04:19:34","commitOrder":6,"curCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        final StreamsException exception = assertThrows(\n            StreamsException.class,\n            () -> queue.addRawRecords(records)\n        );\n        assertThat(exception.getCause(), instanceOf(SerializationException.class));\n    }\n","date":"2020-02-13 04:19:34","endLine":258,"groupId":"5602","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowStreamsExceptionWhenKeyDeserializationFails","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/c9/8950ebc108ade517589c53edbfeb7a58e265e9.src","preCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        queue.addRawRecords(records);\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":248,"status":"M"},{"authorDate":"2018-04-18 04:13:15","commitOrder":6,"curCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","date":"2018-04-18 04:13:15","endLine":220,"groupId":"5602","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/48/be2926e93593165ccc1a058a8a694a14ae9e25.src","preCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":213,"status":"N"}],"commitId":"aa0d0ec32ac53099ddf33e04be2a1701e539dffa","commitMessage":"@@@KAFKA-6607: Commit correct offsets for transactional input data (#8091)\n\nReviewers: Guozhang Wang <guozhang@confluent.io>","date":"2020-02-13 04:19:34","modifiedFileCount":"12","status":"M","submitter":"Matthias J. Sax"},{"authorTime":"2021-04-15 05:38:37","codes":[{"authorDate":"2021-04-15 05:38:37","commitOrder":7,"curCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0, 0, key, recordValue,\n                new RecordHeaders(), Optional.empty()));\n\n        final StreamsException exception = assertThrows(\n            StreamsException.class,\n            () -> queue.addRawRecords(records)\n        );\n        assertThat(exception.getCause(), instanceOf(SerializationException.class));\n    }\n","date":"2021-04-15 05:38:37","endLine":274,"groupId":"102292","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"shouldThrowStreamsExceptionWhenKeyDeserializationFails","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/14/2e85a30589a770b0c4cf75ef45b4fa4b06c038.src","preCode":"    public void shouldThrowStreamsExceptionWhenKeyDeserializationFails() {\n        final byte[] key = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, key, recordValue));\n\n        final StreamsException exception = assertThrows(\n            StreamsException.class,\n            () -> queue.addRawRecords(records)\n        );\n        assertThat(exception.getCause(), instanceOf(SerializationException.class));\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":263,"status":"M"},{"authorDate":"2021-04-15 05:38:37","commitOrder":7,"curCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0, 0, recordKey, value,\n                new RecordHeaders(), Optional.empty()));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","date":"2021-04-15 05:38:37","endLine":310,"groupId":"102292","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-kafka-10-0.7/blobInfo/CC_OUT/blobs/14/2e85a30589a770b0c4cf75ef45b4fa4b06c038.src","preCode":"    public void shouldNotThrowStreamsExceptionWhenValueDeserializationFailsWithSkipHandler() {\n        final byte[] value = Serdes.Long().serializer().serialize(\"foo\", 1L);\n        final List<ConsumerRecord<byte[], byte[]>> records = Collections.singletonList(\n            new ConsumerRecord<>(\"topic\", 1, 1, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, recordKey, value));\n\n        queueThatSkipsDeserializeErrors.addRawRecords(records);\n        assertEquals(0, queueThatSkipsDeserializeErrors.size());\n    }\n","realPath":"streams/src/test/java/org/apache/kafka/streams/processor/internals/RecordQueueTest.java","repoName":"kafka","snippetEndLine":0,"snippetStartLine":0,"startLine":302,"status":"M"}],"commitId":"89933f21f204abf75336464d3ac24a4fdd254628","commitMessage":"@@@KAFKA-12612: Remove `checksum` from ConsumerRecord/RecordMetadata for 3.0 (#10470)\n\nThe methods have been deprecated since 0.11 without replacement since\nmessage format 2 moved the checksum to the record batch (instead of the\nrecord).\n\nUnfortunately.  we did not deprecate the constructors that take a checksum\n(even though we intended to) so we cannot remove them. I have deprecated\nthem for removal in 4.0 and added a single non deprecated constructor to\n`ConsumerRecord` and `RecordMetadata` that take all remaining parameters.\n`ConsumerRecord` could do with one additional convenience constructor.  but\nthat requires a KIP and hence should be done separately.\n\nAlso:\n* Removed `ChecksumMessageFormatter`.  which is technically not public\nAPI.  but may have been used with the console consumer.\n* Updated all usages of `ConsumerRecord`/`RecordMetadata` constructors\nto use the non deprecated ones.\n* Added tests for deprecated `ConsumerRecord/`RecordMetadata`\nconstructors.\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>.  David Jacot <djacot@confluent.io>","date":"2021-04-15 05:38:37","modifiedFileCount":"47","status":"M","submitter":"Ismael Juma"}]
